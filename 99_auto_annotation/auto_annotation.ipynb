{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1ZlaKTGHGEWew-Hjo2nzxGg9nYFQTJaYz\n",
      "From (redirected): https://drive.google.com/uc?id=1ZlaKTGHGEWew-Hjo2nzxGg9nYFQTJaYz&confirm=t&uuid=f7879f96-7a32-41dd-bb30-69fb4cc436cb\n",
      "To: /home/seongmin/src/Python_WS/data/dataset.zip\n",
      "100%|██████████| 14.2G/14.2G [03:06<00:00, 76.4MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data/dataset.zip'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#지하 공동구 데이터셋 다운로드\n",
    "\n",
    "import gdown\n",
    "file_id = \"1ZlaKTGHGEWew-Hjo2nzxGg9nYFQTJaYz\"\n",
    "output = \"data/dataset.zip\" # 저장 위치 및 저장할 파일 이름\n",
    "gdown.download(id=file_id, output=output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/dataset.zip\n",
      "  inflating: data/info.json          \n",
      "   creating: data/상수구/\n",
      " extracting: data/상수구/20230719_142337.mp4  \n",
      "  inflating: data/상수구/20230719_142340.mp4  \n",
      " extracting: data/상수구/20230719_142750.mp4  \n",
      "  inflating: data/상수구/20230719_142752.mp4  \n",
      " extracting: data/상수구/20230719_143152.mp4  \n",
      "  inflating: data/상수구/20230719_143154.mp4  \n",
      " extracting: data/상수구/20230719_143627.mp4  \n",
      "  inflating: data/상수구/20230719_143628.mp4  \n",
      " extracting: data/상수구/20230719_144153.mp4  \n",
      "  inflating: data/상수구/20230719_144155.mp4  \n",
      " extracting: data/상수구/20230719_144702.mp4  \n",
      "  inflating: data/상수구/20230719_144705.mp4  \n",
      " extracting: data/상수구/20230719_145215.mp4  \n",
      "  inflating: data/상수구/20230719_145217.mp4  \n",
      " extracting: data/상수구/20230719_145656.mp4  \n",
      "  inflating: data/상수구/20230719_145657.mp4  \n",
      "  inflating: data/상수구/20230719_151645.mp4  \n",
      " extracting: data/상수구/20230719_151646.mp4  \n",
      " extracting: data/상수구/20230719_152224.mp4  \n",
      "  inflating: data/상수구/20230719_152226.mp4  \n",
      " extracting: data/상수구/20230719_152802.mp4  \n",
      "  inflating: data/상수구/20230719_152804.mp4  \n",
      "   creating: data/전력구/\n",
      " extracting: data/전력구/20230719_154618.mp4  \n",
      " extracting: data/전력구/20230719_155056.mp4  \n",
      " extracting: data/전력구/20230719_155613.mp4  \n",
      " extracting: data/전력구/20230719_160305.mp4  \n",
      " extracting: data/전력구/20230719_161105.mp4  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 압축 파일 풀기\n",
    "\n",
    "import os\n",
    "file_name = \"data/dataset.zip\"\n",
    "output_dir = \"data/\"\n",
    "os.system(\"unzip \"+file_name+\" -d \"+output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 이미지로 분할해 저장\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from time import localtime, strftime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/seongmin/src/Python_WS\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 영상을 가져와 지정한 프레임으로 이미지로 잘라 저장\n",
    "\n",
    "def get_image(path, file_name, label):\n",
    "  fps = 25\n",
    "  print(\"======== 로드할 비디오 경로 : \", path)\n",
    "  if path:\n",
    "    filepath = path\n",
    "  else:\n",
    "    filepath = ''\n",
    "    \n",
    "  video = cv2.VideoCapture(filepath)\n",
    "  \n",
    "  if not video.isOpened():\n",
    "    print(\"파일 에러 : \", filepath)\n",
    "    exit(0)\n",
    "  \n",
    "  try:\n",
    "    if not os.path.exists(f'/home/seongmin/src/Python_WS/data/{label}/{file_name}'):\n",
    "      os.mkdir(f'/home/seongmin/src/Python_WS/data/{label}/{file_name}')\n",
    "  except OSError:\n",
    "    print(\"해당 폴더가 이미 존재합니다 : \" + file_name)\n",
    "    \n",
    "  while(video.isOpened()):\n",
    "    ret, img = video.read()\n",
    "    if ret:      \n",
    "      if(int(video.get(1)) % int(fps) == 0):\n",
    "        if not img is None:  # 이미지가 비어있는지 확인\n",
    "          try:\n",
    "            cv2.imwrite(f'/home/seongmin/src/Python_WS/data/{label}/{file_name}/{str(int(video.get(1)))}.jpg', img)\n",
    "          except Exception as e:\n",
    "            print(\"---------------------------------------------- error 발생 ------------------------------------\")\n",
    "            print(e)\n",
    "          data = {'image': img, \"filename\": f\"{str(int(video.get(1)))}\"}\n",
    "          print(\"저장된 프레임 넘버 : \", str(int(video.get(1))))\n",
    "          yield data\n",
    "      if(ret == False):\n",
    "        break\n",
    "    \n",
    "    video.release()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인자로 받은 경로에 mp4 파일을 모두 반환\n",
    "\n",
    "def get_jpg_files_in_directory(directory):\n",
    "  print(\"directory : \", directory)\n",
    "  return glob.glob(directory + '/**/*.mp4', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory :  /home/seongmin/src/Python_WS/data/water_tunnel\n",
      "===files :  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 0item [00:00, ?item/s]\n"
     ]
    }
   ],
   "source": [
    "# 상수구 이미지 분할 수행\n",
    "directory_path = '/home/seongmin/src/Python_WS/data/water_tunnel'\n",
    "label = 'water_tunnel'\n",
    "files = get_jpg_files_in_directory(directory_path)\n",
    "print(\"===files : \", files)\n",
    "files = sorted(files)\n",
    "for file in files:\n",
    "  print(file)\n",
    "\n",
    "\n",
    "for f in tqdm(files, desc=\"Processing\", unit=\"item\"):\n",
    "  print(\"full_path : \", f)\n",
    "  file_name = f.split('/')[-1].split('.')[0]\n",
    "  print(\"file_name : \", file_name)\n",
    "  for i in get_image(f, file_name, label):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files :  ['/home/seongmin/src/Python_WS/data/electric_tunnel/20230719_155056.mp4', '/home/seongmin/src/Python_WS/data/electric_tunnel/20230719_160305.mp4', '/home/seongmin/src/Python_WS/data/electric_tunnel/20230719_154618.mp4', '/home/seongmin/src/Python_WS/data/electric_tunnel/20230719_155613.mp4', '/home/seongmin/src/Python_WS/data/electric_tunnel/20230719_161105.mp4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/5 [00:00<?, ?item/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_path :  /home/seongmin/src/Python_WS/data/electric_tunnel/20230719_155056.mp4\n",
      "file_name :  20230719_155056\n",
      "======== 로드할 비디오 경로 :  /home/seongmin/src/Python_WS/data/electric_tunnel/20230719_155056.mp4\n",
      "저장된 프레임 넘버 :  25\n",
      "저장된 프레임 넘버 :  50\n",
      "저장된 프레임 넘버 :  75\n",
      "저장된 프레임 넘버 :  100\n",
      "저장된 프레임 넘버 :  125\n",
      "저장된 프레임 넘버 :  150\n",
      "저장된 프레임 넘버 :  175\n",
      "저장된 프레임 넘버 :  200\n",
      "저장된 프레임 넘버 :  225\n",
      "저장된 프레임 넘버 :  250\n",
      "저장된 프레임 넘버 :  275\n",
      "저장된 프레임 넘버 :  300\n",
      "저장된 프레임 넘버 :  325\n",
      "저장된 프레임 넘버 :  350\n",
      "저장된 프레임 넘버 :  375\n",
      "저장된 프레임 넘버 :  400\n",
      "저장된 프레임 넘버 :  425\n",
      "저장된 프레임 넘버 :  450\n",
      "저장된 프레임 넘버 :  475\n",
      "저장된 프레임 넘버 :  500\n",
      "저장된 프레임 넘버 :  525\n",
      "저장된 프레임 넘버 :  550\n",
      "저장된 프레임 넘버 :  575\n",
      "저장된 프레임 넘버 :  600\n",
      "저장된 프레임 넘버 :  625\n",
      "저장된 프레임 넘버 :  650\n",
      "저장된 프레임 넘버 :  675\n",
      "저장된 프레임 넘버 :  700\n",
      "저장된 프레임 넘버 :  725\n",
      "저장된 프레임 넘버 :  750\n",
      "저장된 프레임 넘버 :  775\n",
      "저장된 프레임 넘버 :  800\n",
      "저장된 프레임 넘버 :  825\n",
      "저장된 프레임 넘버 :  850\n",
      "저장된 프레임 넘버 :  875\n",
      "저장된 프레임 넘버 :  900\n",
      "저장된 프레임 넘버 :  925\n",
      "저장된 프레임 넘버 :  950\n",
      "저장된 프레임 넘버 :  975\n",
      "저장된 프레임 넘버 :  1000\n",
      "저장된 프레임 넘버 :  1025\n",
      "저장된 프레임 넘버 :  1050\n",
      "저장된 프레임 넘버 :  1075\n",
      "저장된 프레임 넘버 :  1100\n",
      "저장된 프레임 넘버 :  1125\n",
      "저장된 프레임 넘버 :  1150\n",
      "저장된 프레임 넘버 :  1175\n",
      "저장된 프레임 넘버 :  1200\n",
      "저장된 프레임 넘버 :  1225\n",
      "저장된 프레임 넘버 :  1250\n",
      "저장된 프레임 넘버 :  1275\n",
      "저장된 프레임 넘버 :  1300\n",
      "저장된 프레임 넘버 :  1325\n",
      "저장된 프레임 넘버 :  1350\n",
      "저장된 프레임 넘버 :  1375\n",
      "저장된 프레임 넘버 :  1400\n",
      "저장된 프레임 넘버 :  1425\n",
      "저장된 프레임 넘버 :  1450\n",
      "저장된 프레임 넘버 :  1475\n",
      "저장된 프레임 넘버 :  1500\n",
      "저장된 프레임 넘버 :  1525\n",
      "저장된 프레임 넘버 :  1550\n",
      "저장된 프레임 넘버 :  1575\n",
      "저장된 프레임 넘버 :  1600\n",
      "저장된 프레임 넘버 :  1625\n",
      "저장된 프레임 넘버 :  1650\n",
      "저장된 프레임 넘버 :  1675\n",
      "저장된 프레임 넘버 :  1700\n",
      "저장된 프레임 넘버 :  1725\n",
      "저장된 프레임 넘버 :  1750\n",
      "저장된 프레임 넘버 :  1775\n",
      "저장된 프레임 넘버 :  1800\n",
      "저장된 프레임 넘버 :  1825\n",
      "저장된 프레임 넘버 :  1850\n",
      "저장된 프레임 넘버 :  1875\n",
      "저장된 프레임 넘버 :  1900\n",
      "저장된 프레임 넘버 :  1925\n",
      "저장된 프레임 넘버 :  1950\n",
      "저장된 프레임 넘버 :  1975\n",
      "저장된 프레임 넘버 :  2000\n",
      "저장된 프레임 넘버 :  2025\n",
      "저장된 프레임 넘버 :  2050\n",
      "저장된 프레임 넘버 :  2075\n",
      "저장된 프레임 넘버 :  2100\n",
      "저장된 프레임 넘버 :  2125\n",
      "저장된 프레임 넘버 :  2150\n",
      "저장된 프레임 넘버 :  2175\n",
      "저장된 프레임 넘버 :  2200\n",
      "저장된 프레임 넘버 :  2225\n",
      "저장된 프레임 넘버 :  2250\n",
      "저장된 프레임 넘버 :  2275\n",
      "저장된 프레임 넘버 :  2300\n",
      "저장된 프레임 넘버 :  2325\n",
      "저장된 프레임 넘버 :  2350\n",
      "저장된 프레임 넘버 :  2375\n",
      "저장된 프레임 넘버 :  2400\n",
      "저장된 프레임 넘버 :  2425\n",
      "저장된 프레임 넘버 :  2450\n",
      "저장된 프레임 넘버 :  2475\n",
      "저장된 프레임 넘버 :  2500\n",
      "저장된 프레임 넘버 :  2525\n",
      "저장된 프레임 넘버 :  2550\n",
      "저장된 프레임 넘버 :  2575\n",
      "저장된 프레임 넘버 :  2600\n",
      "저장된 프레임 넘버 :  2625\n",
      "저장된 프레임 넘버 :  2650\n",
      "저장된 프레임 넘버 :  2675\n",
      "저장된 프레임 넘버 :  2700\n",
      "저장된 프레임 넘버 :  2725\n",
      "저장된 프레임 넘버 :  2750\n",
      "저장된 프레임 넘버 :  2775\n",
      "저장된 프레임 넘버 :  2800\n",
      "저장된 프레임 넘버 :  2825\n",
      "저장된 프레임 넘버 :  2850\n",
      "저장된 프레임 넘버 :  2875\n",
      "저장된 프레임 넘버 :  2900\n",
      "저장된 프레임 넘버 :  2925\n",
      "저장된 프레임 넘버 :  2950\n",
      "저장된 프레임 넘버 :  2975\n",
      "저장된 프레임 넘버 :  3000\n",
      "저장된 프레임 넘버 :  3025\n",
      "저장된 프레임 넘버 :  3050\n",
      "저장된 프레임 넘버 :  3075\n",
      "저장된 프레임 넘버 :  3100\n",
      "저장된 프레임 넘버 :  3125\n",
      "저장된 프레임 넘버 :  3150\n",
      "저장된 프레임 넘버 :  3175\n",
      "저장된 프레임 넘버 :  3200\n",
      "저장된 프레임 넘버 :  3225\n",
      "저장된 프레임 넘버 :  3250\n",
      "저장된 프레임 넘버 :  3275\n",
      "저장된 프레임 넘버 :  3300\n",
      "저장된 프레임 넘버 :  3325\n",
      "저장된 프레임 넘버 :  3350\n",
      "저장된 프레임 넘버 :  3375\n",
      "저장된 프레임 넘버 :  3400\n",
      "저장된 프레임 넘버 :  3425\n",
      "저장된 프레임 넘버 :  3450\n",
      "저장된 프레임 넘버 :  3475\n",
      "저장된 프레임 넘버 :  3500\n",
      "저장된 프레임 넘버 :  3525\n",
      "저장된 프레임 넘버 :  3550\n",
      "저장된 프레임 넘버 :  3575\n",
      "저장된 프레임 넘버 :  3600\n",
      "저장된 프레임 넘버 :  3625\n",
      "저장된 프레임 넘버 :  3650\n",
      "저장된 프레임 넘버 :  3675\n",
      "저장된 프레임 넘버 :  3700\n",
      "저장된 프레임 넘버 :  3725\n",
      "저장된 프레임 넘버 :  3750\n",
      "저장된 프레임 넘버 :  3775\n",
      "저장된 프레임 넘버 :  3800\n",
      "저장된 프레임 넘버 :  3825\n",
      "저장된 프레임 넘버 :  3850\n",
      "저장된 프레임 넘버 :  3875\n",
      "저장된 프레임 넘버 :  3900\n",
      "저장된 프레임 넘버 :  3925\n",
      "저장된 프레임 넘버 :  3950\n",
      "저장된 프레임 넘버 :  3975\n",
      "저장된 프레임 넘버 :  4000\n",
      "저장된 프레임 넘버 :  4025\n",
      "저장된 프레임 넘버 :  4050\n",
      "저장된 프레임 넘버 :  4075\n",
      "저장된 프레임 넘버 :  4100\n",
      "저장된 프레임 넘버 :  4125\n",
      "저장된 프레임 넘버 :  4150\n",
      "저장된 프레임 넘버 :  4175\n",
      "저장된 프레임 넘버 :  4200\n",
      "저장된 프레임 넘버 :  4225\n",
      "저장된 프레임 넘버 :  4250\n",
      "저장된 프레임 넘버 :  4275\n",
      "저장된 프레임 넘버 :  4300\n",
      "저장된 프레임 넘버 :  4325\n",
      "저장된 프레임 넘버 :  4350\n",
      "저장된 프레임 넘버 :  4375\n",
      "저장된 프레임 넘버 :  4400\n",
      "저장된 프레임 넘버 :  4425\n",
      "저장된 프레임 넘버 :  4450\n",
      "저장된 프레임 넘버 :  4475\n",
      "저장된 프레임 넘버 :  4500\n",
      "저장된 프레임 넘버 :  4525\n",
      "저장된 프레임 넘버 :  4550\n",
      "저장된 프레임 넘버 :  4575\n",
      "저장된 프레임 넘버 :  4600\n",
      "저장된 프레임 넘버 :  4625\n",
      "저장된 프레임 넘버 :  4650\n",
      "저장된 프레임 넘버 :  4675\n",
      "저장된 프레임 넘버 :  4700\n",
      "저장된 프레임 넘버 :  4725\n",
      "저장된 프레임 넘버 :  4750\n",
      "저장된 프레임 넘버 :  4775\n",
      "저장된 프레임 넘버 :  4800\n",
      "저장된 프레임 넘버 :  4825\n",
      "저장된 프레임 넘버 :  4850\n",
      "저장된 프레임 넘버 :  4875\n",
      "저장된 프레임 넘버 :  4900\n",
      "저장된 프레임 넘버 :  4925\n",
      "저장된 프레임 넘버 :  4950\n",
      "저장된 프레임 넘버 :  4975\n",
      "저장된 프레임 넘버 :  5000\n",
      "저장된 프레임 넘버 :  5025\n",
      "저장된 프레임 넘버 :  5050\n",
      "저장된 프레임 넘버 :  5075\n",
      "저장된 프레임 넘버 :  5100\n",
      "저장된 프레임 넘버 :  5125\n",
      "저장된 프레임 넘버 :  5150\n",
      "저장된 프레임 넘버 :  5175\n",
      "저장된 프레임 넘버 :  5200\n",
      "저장된 프레임 넘버 :  5225\n",
      "저장된 프레임 넘버 :  5250\n",
      "저장된 프레임 넘버 :  5275\n",
      "저장된 프레임 넘버 :  5300\n",
      "저장된 프레임 넘버 :  5325\n",
      "저장된 프레임 넘버 :  5350\n",
      "저장된 프레임 넘버 :  5375\n",
      "저장된 프레임 넘버 :  5400\n",
      "저장된 프레임 넘버 :  5425\n",
      "저장된 프레임 넘버 :  5450\n",
      "저장된 프레임 넘버 :  5475\n",
      "저장된 프레임 넘버 :  5500\n",
      "저장된 프레임 넘버 :  5525\n",
      "저장된 프레임 넘버 :  5550\n",
      "저장된 프레임 넘버 :  5575\n",
      "저장된 프레임 넘버 :  5600\n",
      "저장된 프레임 넘버 :  5625\n",
      "저장된 프레임 넘버 :  5650\n",
      "저장된 프레임 넘버 :  5675\n",
      "저장된 프레임 넘버 :  5700\n",
      "저장된 프레임 넘버 :  5725\n",
      "저장된 프레임 넘버 :  5750\n",
      "저장된 프레임 넘버 :  5775\n",
      "저장된 프레임 넘버 :  5800\n",
      "저장된 프레임 넘버 :  5825\n",
      "저장된 프레임 넘버 :  5850\n",
      "저장된 프레임 넘버 :  5875\n",
      "저장된 프레임 넘버 :  5900\n",
      "저장된 프레임 넘버 :  5925\n",
      "저장된 프레임 넘버 :  5950\n",
      "저장된 프레임 넘버 :  5975\n",
      "저장된 프레임 넘버 :  6000\n",
      "저장된 프레임 넘버 :  6025\n",
      "저장된 프레임 넘버 :  6050\n",
      "저장된 프레임 넘버 :  6075\n",
      "저장된 프레임 넘버 :  6100\n",
      "저장된 프레임 넘버 :  6125\n",
      "저장된 프레임 넘버 :  6150\n",
      "저장된 프레임 넘버 :  6175\n",
      "저장된 프레임 넘버 :  6200\n",
      "저장된 프레임 넘버 :  6225\n",
      "저장된 프레임 넘버 :  6250\n",
      "저장된 프레임 넘버 :  6275\n",
      "저장된 프레임 넘버 :  6300\n",
      "저장된 프레임 넘버 :  6325\n",
      "저장된 프레임 넘버 :  6350\n",
      "저장된 프레임 넘버 :  6375\n",
      "저장된 프레임 넘버 :  6400\n",
      "저장된 프레임 넘버 :  6425\n",
      "저장된 프레임 넘버 :  6450\n",
      "저장된 프레임 넘버 :  6475\n",
      "저장된 프레임 넘버 :  6500\n",
      "저장된 프레임 넘버 :  6525\n",
      "저장된 프레임 넘버 :  6550\n",
      "저장된 프레임 넘버 :  6575\n",
      "저장된 프레임 넘버 :  6600\n",
      "저장된 프레임 넘버 :  6625\n",
      "저장된 프레임 넘버 :  6650\n",
      "저장된 프레임 넘버 :  6675\n",
      "저장된 프레임 넘버 :  6700\n",
      "저장된 프레임 넘버 :  6725\n",
      "저장된 프레임 넘버 :  6750\n",
      "저장된 프레임 넘버 :  6775\n",
      "저장된 프레임 넘버 :  6800\n",
      "저장된 프레임 넘버 :  6825\n",
      "저장된 프레임 넘버 :  6850\n",
      "저장된 프레임 넘버 :  6875\n",
      "저장된 프레임 넘버 :  6900\n",
      "저장된 프레임 넘버 :  6925\n",
      "저장된 프레임 넘버 :  6950\n",
      "저장된 프레임 넘버 :  6975\n",
      "저장된 프레임 넘버 :  7000\n",
      "저장된 프레임 넘버 :  7025\n",
      "저장된 프레임 넘버 :  7050\n",
      "저장된 프레임 넘버 :  7075\n",
      "저장된 프레임 넘버 :  7100\n",
      "저장된 프레임 넘버 :  7125\n",
      "저장된 프레임 넘버 :  7150\n",
      "저장된 프레임 넘버 :  7175\n",
      "저장된 프레임 넘버 :  7200\n",
      "저장된 프레임 넘버 :  7225\n",
      "저장된 프레임 넘버 :  7250\n",
      "저장된 프레임 넘버 :  7275\n",
      "저장된 프레임 넘버 :  7300\n",
      "저장된 프레임 넘버 :  7325\n",
      "저장된 프레임 넘버 :  7350\n",
      "저장된 프레임 넘버 :  7375\n",
      "저장된 프레임 넘버 :  7400\n",
      "저장된 프레임 넘버 :  7425\n",
      "저장된 프레임 넘버 :  7450\n",
      "저장된 프레임 넘버 :  7475\n",
      "저장된 프레임 넘버 :  7500\n",
      "저장된 프레임 넘버 :  7525\n",
      "저장된 프레임 넘버 :  7550\n",
      "저장된 프레임 넘버 :  7575\n",
      "저장된 프레임 넘버 :  7600\n",
      "저장된 프레임 넘버 :  7625\n",
      "저장된 프레임 넘버 :  7650\n",
      "저장된 프레임 넘버 :  7675\n",
      "저장된 프레임 넘버 :  7700\n",
      "저장된 프레임 넘버 :  7725\n",
      "저장된 프레임 넘버 :  7750\n",
      "저장된 프레임 넘버 :  7775\n",
      "저장된 프레임 넘버 :  7800\n",
      "저장된 프레임 넘버 :  7825\n",
      "저장된 프레임 넘버 :  7850\n",
      "저장된 프레임 넘버 :  7875\n",
      "저장된 프레임 넘버 :  7900\n",
      "저장된 프레임 넘버 :  7925\n",
      "저장된 프레임 넘버 :  7950\n",
      "저장된 프레임 넘버 :  7975\n",
      "저장된 프레임 넘버 :  8000\n",
      "저장된 프레임 넘버 :  8025\n",
      "저장된 프레임 넘버 :  8050\n",
      "저장된 프레임 넘버 :  8075\n",
      "저장된 프레임 넘버 :  8100\n",
      "저장된 프레임 넘버 :  8125\n",
      "저장된 프레임 넘버 :  8150\n",
      "저장된 프레임 넘버 :  8175\n",
      "저장된 프레임 넘버 :  8200\n",
      "저장된 프레임 넘버 :  8225\n",
      "저장된 프레임 넘버 :  8250\n",
      "저장된 프레임 넘버 :  8275\n",
      "저장된 프레임 넘버 :  8300\n",
      "저장된 프레임 넘버 :  8325\n",
      "저장된 프레임 넘버 :  8350\n",
      "저장된 프레임 넘버 :  8375\n",
      "저장된 프레임 넘버 :  8400\n",
      "저장된 프레임 넘버 :  8425\n",
      "저장된 프레임 넘버 :  8450\n",
      "저장된 프레임 넘버 :  8475\n",
      "저장된 프레임 넘버 :  8500\n",
      "저장된 프레임 넘버 :  8525\n",
      "저장된 프레임 넘버 :  8550\n",
      "저장된 프레임 넘버 :  8575\n",
      "저장된 프레임 넘버 :  8600\n",
      "저장된 프레임 넘버 :  8625\n",
      "저장된 프레임 넘버 :  8650\n",
      "저장된 프레임 넘버 :  8675\n",
      "저장된 프레임 넘버 :  8700\n",
      "저장된 프레임 넘버 :  8725\n",
      "저장된 프레임 넘버 :  8750\n",
      "저장된 프레임 넘버 :  8775\n",
      "저장된 프레임 넘버 :  8800\n",
      "저장된 프레임 넘버 :  8825\n",
      "저장된 프레임 넘버 :  8850\n",
      "저장된 프레임 넘버 :  8875\n",
      "저장된 프레임 넘버 :  8900\n",
      "저장된 프레임 넘버 :  8925\n",
      "저장된 프레임 넘버 :  8950\n",
      "저장된 프레임 넘버 :  8975\n",
      "저장된 프레임 넘버 :  9000\n",
      "저장된 프레임 넘버 :  9025\n",
      "저장된 프레임 넘버 :  9050\n",
      "저장된 프레임 넘버 :  9075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  20%|██        | 1/5 [00:34<02:19, 34.76s/item]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 프레임 넘버 :  9100\n",
      "저장된 프레임 넘버 :  9125\n",
      "full_path :  /home/seongmin/src/Python_WS/data/electric_tunnel/20230719_160305.mp4\n",
      "file_name :  20230719_160305\n",
      "======== 로드할 비디오 경로 :  /home/seongmin/src/Python_WS/data/electric_tunnel/20230719_160305.mp4\n",
      "저장된 프레임 넘버 :  25\n",
      "저장된 프레임 넘버 :  50\n",
      "저장된 프레임 넘버 :  75\n",
      "저장된 프레임 넘버 :  100\n",
      "저장된 프레임 넘버 :  125\n",
      "저장된 프레임 넘버 :  150\n",
      "저장된 프레임 넘버 :  175\n",
      "저장된 프레임 넘버 :  200\n",
      "저장된 프레임 넘버 :  225\n",
      "저장된 프레임 넘버 :  250\n",
      "저장된 프레임 넘버 :  275\n",
      "저장된 프레임 넘버 :  300\n",
      "저장된 프레임 넘버 :  325\n",
      "저장된 프레임 넘버 :  350\n",
      "저장된 프레임 넘버 :  375\n",
      "저장된 프레임 넘버 :  400\n",
      "저장된 프레임 넘버 :  425\n",
      "저장된 프레임 넘버 :  450\n",
      "저장된 프레임 넘버 :  475\n",
      "저장된 프레임 넘버 :  500\n",
      "저장된 프레임 넘버 :  525\n",
      "저장된 프레임 넘버 :  550\n",
      "저장된 프레임 넘버 :  575\n",
      "저장된 프레임 넘버 :  600\n",
      "저장된 프레임 넘버 :  625\n",
      "저장된 프레임 넘버 :  650\n",
      "저장된 프레임 넘버 :  675\n",
      "저장된 프레임 넘버 :  700\n",
      "저장된 프레임 넘버 :  725\n",
      "저장된 프레임 넘버 :  750\n",
      "저장된 프레임 넘버 :  775\n",
      "저장된 프레임 넘버 :  800\n",
      "저장된 프레임 넘버 :  825\n",
      "저장된 프레임 넘버 :  850\n",
      "저장된 프레임 넘버 :  875\n",
      "저장된 프레임 넘버 :  900\n",
      "저장된 프레임 넘버 :  925\n",
      "저장된 프레임 넘버 :  950\n",
      "저장된 프레임 넘버 :  975\n",
      "저장된 프레임 넘버 :  1000\n",
      "저장된 프레임 넘버 :  1025\n",
      "저장된 프레임 넘버 :  1050\n",
      "저장된 프레임 넘버 :  1075\n",
      "저장된 프레임 넘버 :  1100\n",
      "저장된 프레임 넘버 :  1125\n",
      "저장된 프레임 넘버 :  1150\n",
      "저장된 프레임 넘버 :  1175\n",
      "저장된 프레임 넘버 :  1200\n",
      "저장된 프레임 넘버 :  1225\n",
      "저장된 프레임 넘버 :  1250\n",
      "저장된 프레임 넘버 :  1275\n",
      "저장된 프레임 넘버 :  1300\n",
      "저장된 프레임 넘버 :  1325\n",
      "저장된 프레임 넘버 :  1350\n",
      "저장된 프레임 넘버 :  1375\n",
      "저장된 프레임 넘버 :  1400\n",
      "저장된 프레임 넘버 :  1425\n",
      "저장된 프레임 넘버 :  1450\n",
      "저장된 프레임 넘버 :  1475\n",
      "저장된 프레임 넘버 :  1500\n",
      "저장된 프레임 넘버 :  1525\n",
      "저장된 프레임 넘버 :  1550\n",
      "저장된 프레임 넘버 :  1575\n",
      "저장된 프레임 넘버 :  1600\n",
      "저장된 프레임 넘버 :  1625\n",
      "저장된 프레임 넘버 :  1650\n",
      "저장된 프레임 넘버 :  1675\n",
      "저장된 프레임 넘버 :  1700\n",
      "저장된 프레임 넘버 :  1725\n",
      "저장된 프레임 넘버 :  1750\n",
      "저장된 프레임 넘버 :  1775\n",
      "저장된 프레임 넘버 :  1800\n",
      "저장된 프레임 넘버 :  1825\n",
      "저장된 프레임 넘버 :  1850\n",
      "저장된 프레임 넘버 :  1875\n",
      "저장된 프레임 넘버 :  1900\n",
      "저장된 프레임 넘버 :  1925\n",
      "저장된 프레임 넘버 :  1950\n",
      "저장된 프레임 넘버 :  1975\n",
      "저장된 프레임 넘버 :  2000\n",
      "저장된 프레임 넘버 :  2025\n",
      "저장된 프레임 넘버 :  2050\n",
      "저장된 프레임 넘버 :  2075\n",
      "저장된 프레임 넘버 :  2100\n",
      "저장된 프레임 넘버 :  2125\n",
      "저장된 프레임 넘버 :  2150\n",
      "저장된 프레임 넘버 :  2175\n",
      "저장된 프레임 넘버 :  2200\n",
      "저장된 프레임 넘버 :  2225\n",
      "저장된 프레임 넘버 :  2250\n",
      "저장된 프레임 넘버 :  2275\n",
      "저장된 프레임 넘버 :  2300\n",
      "저장된 프레임 넘버 :  2325\n",
      "저장된 프레임 넘버 :  2350\n",
      "저장된 프레임 넘버 :  2375\n",
      "저장된 프레임 넘버 :  2400\n",
      "저장된 프레임 넘버 :  2425\n",
      "저장된 프레임 넘버 :  2450\n",
      "저장된 프레임 넘버 :  2475\n",
      "저장된 프레임 넘버 :  2500\n",
      "저장된 프레임 넘버 :  2525\n",
      "저장된 프레임 넘버 :  2550\n",
      "저장된 프레임 넘버 :  2575\n",
      "저장된 프레임 넘버 :  2600\n",
      "저장된 프레임 넘버 :  2625\n",
      "저장된 프레임 넘버 :  2650\n",
      "저장된 프레임 넘버 :  2675\n",
      "저장된 프레임 넘버 :  2700\n",
      "저장된 프레임 넘버 :  2725\n",
      "저장된 프레임 넘버 :  2750\n",
      "저장된 프레임 넘버 :  2775\n",
      "저장된 프레임 넘버 :  2800\n",
      "저장된 프레임 넘버 :  2825\n",
      "저장된 프레임 넘버 :  2850\n",
      "저장된 프레임 넘버 :  2875\n",
      "저장된 프레임 넘버 :  2900\n",
      "저장된 프레임 넘버 :  2925\n",
      "저장된 프레임 넘버 :  2950\n",
      "저장된 프레임 넘버 :  2975\n",
      "저장된 프레임 넘버 :  3000\n",
      "저장된 프레임 넘버 :  3025\n",
      "저장된 프레임 넘버 :  3050\n",
      "저장된 프레임 넘버 :  3075\n",
      "저장된 프레임 넘버 :  3100\n",
      "저장된 프레임 넘버 :  3125\n",
      "저장된 프레임 넘버 :  3150\n",
      "저장된 프레임 넘버 :  3175\n",
      "저장된 프레임 넘버 :  3200\n",
      "저장된 프레임 넘버 :  3225\n",
      "저장된 프레임 넘버 :  3250\n",
      "저장된 프레임 넘버 :  3275\n",
      "저장된 프레임 넘버 :  3300\n",
      "저장된 프레임 넘버 :  3325\n",
      "저장된 프레임 넘버 :  3350\n",
      "저장된 프레임 넘버 :  3375\n",
      "저장된 프레임 넘버 :  3400\n",
      "저장된 프레임 넘버 :  3425\n",
      "저장된 프레임 넘버 :  3450\n",
      "저장된 프레임 넘버 :  3475\n",
      "저장된 프레임 넘버 :  3500\n",
      "저장된 프레임 넘버 :  3525\n",
      "저장된 프레임 넘버 :  3550\n",
      "저장된 프레임 넘버 :  3575\n",
      "저장된 프레임 넘버 :  3600\n",
      "저장된 프레임 넘버 :  3625\n",
      "저장된 프레임 넘버 :  3650\n",
      "저장된 프레임 넘버 :  3675\n",
      "저장된 프레임 넘버 :  3700\n",
      "저장된 프레임 넘버 :  3725\n",
      "저장된 프레임 넘버 :  3750\n",
      "저장된 프레임 넘버 :  3775\n",
      "저장된 프레임 넘버 :  3800\n",
      "저장된 프레임 넘버 :  3825\n",
      "저장된 프레임 넘버 :  3850\n",
      "저장된 프레임 넘버 :  3875\n",
      "저장된 프레임 넘버 :  3900\n",
      "저장된 프레임 넘버 :  3925\n",
      "저장된 프레임 넘버 :  3950\n",
      "저장된 프레임 넘버 :  3975\n",
      "저장된 프레임 넘버 :  4000\n",
      "저장된 프레임 넘버 :  4025\n",
      "저장된 프레임 넘버 :  4050\n",
      "저장된 프레임 넘버 :  4075\n",
      "저장된 프레임 넘버 :  4100\n",
      "저장된 프레임 넘버 :  4125\n",
      "저장된 프레임 넘버 :  4150\n",
      "저장된 프레임 넘버 :  4175\n",
      "저장된 프레임 넘버 :  4200\n",
      "저장된 프레임 넘버 :  4225\n",
      "저장된 프레임 넘버 :  4250\n",
      "저장된 프레임 넘버 :  4275\n",
      "저장된 프레임 넘버 :  4300\n",
      "저장된 프레임 넘버 :  4325\n",
      "저장된 프레임 넘버 :  4350\n",
      "저장된 프레임 넘버 :  4375\n",
      "저장된 프레임 넘버 :  4400\n",
      "저장된 프레임 넘버 :  4425\n",
      "저장된 프레임 넘버 :  4450\n",
      "저장된 프레임 넘버 :  4475\n",
      "저장된 프레임 넘버 :  4500\n",
      "저장된 프레임 넘버 :  4525\n",
      "저장된 프레임 넘버 :  4550\n",
      "저장된 프레임 넘버 :  4575\n",
      "저장된 프레임 넘버 :  4600\n",
      "저장된 프레임 넘버 :  4625\n",
      "저장된 프레임 넘버 :  4650\n",
      "저장된 프레임 넘버 :  4675\n",
      "저장된 프레임 넘버 :  4700\n",
      "저장된 프레임 넘버 :  4725\n",
      "저장된 프레임 넘버 :  4750\n",
      "저장된 프레임 넘버 :  4775\n",
      "저장된 프레임 넘버 :  4800\n",
      "저장된 프레임 넘버 :  4825\n",
      "저장된 프레임 넘버 :  4850\n",
      "저장된 프레임 넘버 :  4875\n",
      "저장된 프레임 넘버 :  4900\n",
      "저장된 프레임 넘버 :  4925\n",
      "저장된 프레임 넘버 :  4950\n",
      "저장된 프레임 넘버 :  4975\n",
      "저장된 프레임 넘버 :  5000\n",
      "저장된 프레임 넘버 :  5025\n",
      "저장된 프레임 넘버 :  5050\n",
      "저장된 프레임 넘버 :  5075\n",
      "저장된 프레임 넘버 :  5100\n",
      "저장된 프레임 넘버 :  5125\n",
      "저장된 프레임 넘버 :  5150\n",
      "저장된 프레임 넘버 :  5175\n",
      "저장된 프레임 넘버 :  5200\n",
      "저장된 프레임 넘버 :  5225\n",
      "저장된 프레임 넘버 :  5250\n",
      "저장된 프레임 넘버 :  5275\n",
      "저장된 프레임 넘버 :  5300\n",
      "저장된 프레임 넘버 :  5325\n",
      "저장된 프레임 넘버 :  5350\n",
      "저장된 프레임 넘버 :  5375\n",
      "저장된 프레임 넘버 :  5400\n",
      "저장된 프레임 넘버 :  5425\n",
      "저장된 프레임 넘버 :  5450\n",
      "저장된 프레임 넘버 :  5475\n",
      "저장된 프레임 넘버 :  5500\n",
      "저장된 프레임 넘버 :  5525\n",
      "저장된 프레임 넘버 :  5550\n",
      "저장된 프레임 넘버 :  5575\n",
      "저장된 프레임 넘버 :  5600\n",
      "저장된 프레임 넘버 :  5625\n",
      "저장된 프레임 넘버 :  5650\n",
      "저장된 프레임 넘버 :  5675\n",
      "저장된 프레임 넘버 :  5700\n",
      "저장된 프레임 넘버 :  5725\n",
      "저장된 프레임 넘버 :  5750\n",
      "저장된 프레임 넘버 :  5775\n",
      "저장된 프레임 넘버 :  5800\n",
      "저장된 프레임 넘버 :  5825\n",
      "저장된 프레임 넘버 :  5850\n",
      "저장된 프레임 넘버 :  5875\n",
      "저장된 프레임 넘버 :  5900\n",
      "저장된 프레임 넘버 :  5925\n",
      "저장된 프레임 넘버 :  5950\n",
      "저장된 프레임 넘버 :  5975\n",
      "저장된 프레임 넘버 :  6000\n",
      "저장된 프레임 넘버 :  6025\n",
      "저장된 프레임 넘버 :  6050\n",
      "저장된 프레임 넘버 :  6075\n",
      "저장된 프레임 넘버 :  6100\n",
      "저장된 프레임 넘버 :  6125\n",
      "저장된 프레임 넘버 :  6150\n",
      "저장된 프레임 넘버 :  6175\n",
      "저장된 프레임 넘버 :  6200\n",
      "저장된 프레임 넘버 :  6225\n",
      "저장된 프레임 넘버 :  6250\n",
      "저장된 프레임 넘버 :  6275\n",
      "저장된 프레임 넘버 :  6300\n",
      "저장된 프레임 넘버 :  6325\n",
      "저장된 프레임 넘버 :  6350\n",
      "저장된 프레임 넘버 :  6375\n",
      "저장된 프레임 넘버 :  6400\n",
      "저장된 프레임 넘버 :  6425\n",
      "저장된 프레임 넘버 :  6450\n",
      "저장된 프레임 넘버 :  6475\n",
      "저장된 프레임 넘버 :  6500\n",
      "저장된 프레임 넘버 :  6525\n",
      "저장된 프레임 넘버 :  6550\n",
      "저장된 프레임 넘버 :  6575\n",
      "저장된 프레임 넘버 :  6600\n",
      "저장된 프레임 넘버 :  6625\n",
      "저장된 프레임 넘버 :  6650\n",
      "저장된 프레임 넘버 :  6675\n",
      "저장된 프레임 넘버 :  6700\n",
      "저장된 프레임 넘버 :  6725\n",
      "저장된 프레임 넘버 :  6750\n",
      "저장된 프레임 넘버 :  6775\n",
      "저장된 프레임 넘버 :  6800\n",
      "저장된 프레임 넘버 :  6825\n",
      "저장된 프레임 넘버 :  6850\n",
      "저장된 프레임 넘버 :  6875\n",
      "저장된 프레임 넘버 :  6900\n",
      "저장된 프레임 넘버 :  6925\n",
      "저장된 프레임 넘버 :  6950\n",
      "저장된 프레임 넘버 :  6975\n",
      "저장된 프레임 넘버 :  7000\n",
      "저장된 프레임 넘버 :  7025\n",
      "저장된 프레임 넘버 :  7050\n",
      "저장된 프레임 넘버 :  7075\n",
      "저장된 프레임 넘버 :  7100\n",
      "저장된 프레임 넘버 :  7125\n",
      "저장된 프레임 넘버 :  7150\n",
      "저장된 프레임 넘버 :  7175\n",
      "저장된 프레임 넘버 :  7200\n",
      "저장된 프레임 넘버 :  7225\n",
      "저장된 프레임 넘버 :  7250\n",
      "저장된 프레임 넘버 :  7275\n",
      "저장된 프레임 넘버 :  7300\n",
      "저장된 프레임 넘버 :  7325\n",
      "저장된 프레임 넘버 :  7350\n",
      "저장된 프레임 넘버 :  7375\n",
      "저장된 프레임 넘버 :  7400\n",
      "저장된 프레임 넘버 :  7425\n",
      "저장된 프레임 넘버 :  7450\n",
      "저장된 프레임 넘버 :  7475\n",
      "저장된 프레임 넘버 :  7500\n",
      "저장된 프레임 넘버 :  7525\n",
      "저장된 프레임 넘버 :  7550\n",
      "저장된 프레임 넘버 :  7575\n",
      "저장된 프레임 넘버 :  7600\n",
      "저장된 프레임 넘버 :  7625\n",
      "저장된 프레임 넘버 :  7650\n",
      "저장된 프레임 넘버 :  7675\n",
      "저장된 프레임 넘버 :  7700\n",
      "저장된 프레임 넘버 :  7725\n",
      "저장된 프레임 넘버 :  7750\n",
      "저장된 프레임 넘버 :  7775\n",
      "저장된 프레임 넘버 :  7800\n",
      "저장된 프레임 넘버 :  7825\n",
      "저장된 프레임 넘버 :  7850\n",
      "저장된 프레임 넘버 :  7875\n",
      "저장된 프레임 넘버 :  7900\n",
      "저장된 프레임 넘버 :  7925\n",
      "저장된 프레임 넘버 :  7950\n",
      "저장된 프레임 넘버 :  7975\n",
      "저장된 프레임 넘버 :  8000\n",
      "저장된 프레임 넘버 :  8025\n",
      "저장된 프레임 넘버 :  8050\n",
      "저장된 프레임 넘버 :  8075\n",
      "저장된 프레임 넘버 :  8100\n",
      "저장된 프레임 넘버 :  8125\n",
      "저장된 프레임 넘버 :  8150\n",
      "저장된 프레임 넘버 :  8175\n",
      "저장된 프레임 넘버 :  8200\n",
      "저장된 프레임 넘버 :  8225\n",
      "저장된 프레임 넘버 :  8250\n",
      "저장된 프레임 넘버 :  8275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  40%|████      | 2/5 [01:06<01:38, 32.89s/item]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 프레임 넘버 :  8300\n",
      "저장된 프레임 넘버 :  8325\n",
      "full_path :  /home/seongmin/src/Python_WS/data/electric_tunnel/20230719_154618.mp4\n",
      "file_name :  20230719_154618\n",
      "======== 로드할 비디오 경로 :  /home/seongmin/src/Python_WS/data/electric_tunnel/20230719_154618.mp4\n",
      "저장된 프레임 넘버 :  25\n",
      "저장된 프레임 넘버 :  50\n",
      "저장된 프레임 넘버 :  75\n",
      "저장된 프레임 넘버 :  100\n",
      "저장된 프레임 넘버 :  125\n",
      "저장된 프레임 넘버 :  150\n",
      "저장된 프레임 넘버 :  175\n",
      "저장된 프레임 넘버 :  200\n",
      "저장된 프레임 넘버 :  225\n",
      "저장된 프레임 넘버 :  250\n",
      "저장된 프레임 넘버 :  275\n",
      "저장된 프레임 넘버 :  300\n",
      "저장된 프레임 넘버 :  325\n",
      "저장된 프레임 넘버 :  350\n",
      "저장된 프레임 넘버 :  375\n",
      "저장된 프레임 넘버 :  400\n",
      "저장된 프레임 넘버 :  425\n",
      "저장된 프레임 넘버 :  450\n",
      "저장된 프레임 넘버 :  475\n",
      "저장된 프레임 넘버 :  500\n",
      "저장된 프레임 넘버 :  525\n",
      "저장된 프레임 넘버 :  550\n",
      "저장된 프레임 넘버 :  575\n",
      "저장된 프레임 넘버 :  600\n",
      "저장된 프레임 넘버 :  625\n",
      "저장된 프레임 넘버 :  650\n",
      "저장된 프레임 넘버 :  675\n",
      "저장된 프레임 넘버 :  700\n",
      "저장된 프레임 넘버 :  725\n",
      "저장된 프레임 넘버 :  750\n",
      "저장된 프레임 넘버 :  775\n",
      "저장된 프레임 넘버 :  800\n",
      "저장된 프레임 넘버 :  825\n",
      "저장된 프레임 넘버 :  850\n",
      "저장된 프레임 넘버 :  875\n",
      "저장된 프레임 넘버 :  900\n",
      "저장된 프레임 넘버 :  925\n",
      "저장된 프레임 넘버 :  950\n",
      "저장된 프레임 넘버 :  975\n",
      "저장된 프레임 넘버 :  1000\n",
      "저장된 프레임 넘버 :  1025\n",
      "저장된 프레임 넘버 :  1050\n",
      "저장된 프레임 넘버 :  1075\n",
      "저장된 프레임 넘버 :  1100\n",
      "저장된 프레임 넘버 :  1125\n",
      "저장된 프레임 넘버 :  1150\n",
      "저장된 프레임 넘버 :  1175\n",
      "저장된 프레임 넘버 :  1200\n",
      "저장된 프레임 넘버 :  1225\n",
      "저장된 프레임 넘버 :  1250\n",
      "저장된 프레임 넘버 :  1275\n",
      "저장된 프레임 넘버 :  1300\n",
      "저장된 프레임 넘버 :  1325\n",
      "저장된 프레임 넘버 :  1350\n",
      "저장된 프레임 넘버 :  1375\n",
      "저장된 프레임 넘버 :  1400\n",
      "저장된 프레임 넘버 :  1425\n",
      "저장된 프레임 넘버 :  1450\n",
      "저장된 프레임 넘버 :  1475\n",
      "저장된 프레임 넘버 :  1500\n",
      "저장된 프레임 넘버 :  1525\n",
      "저장된 프레임 넘버 :  1550\n",
      "저장된 프레임 넘버 :  1575\n",
      "저장된 프레임 넘버 :  1600\n",
      "저장된 프레임 넘버 :  1625\n",
      "저장된 프레임 넘버 :  1650\n",
      "저장된 프레임 넘버 :  1675\n",
      "저장된 프레임 넘버 :  1700\n",
      "저장된 프레임 넘버 :  1725\n",
      "저장된 프레임 넘버 :  1750\n",
      "저장된 프레임 넘버 :  1775\n",
      "저장된 프레임 넘버 :  1800\n",
      "저장된 프레임 넘버 :  1825\n",
      "저장된 프레임 넘버 :  1850\n",
      "저장된 프레임 넘버 :  1875\n",
      "저장된 프레임 넘버 :  1900\n",
      "저장된 프레임 넘버 :  1925\n",
      "저장된 프레임 넘버 :  1950\n",
      "저장된 프레임 넘버 :  1975\n",
      "저장된 프레임 넘버 :  2000\n",
      "저장된 프레임 넘버 :  2025\n",
      "저장된 프레임 넘버 :  2050\n",
      "저장된 프레임 넘버 :  2075\n",
      "저장된 프레임 넘버 :  2100\n",
      "저장된 프레임 넘버 :  2125\n",
      "저장된 프레임 넘버 :  2150\n",
      "저장된 프레임 넘버 :  2175\n",
      "저장된 프레임 넘버 :  2200\n",
      "저장된 프레임 넘버 :  2225\n",
      "저장된 프레임 넘버 :  2250\n",
      "저장된 프레임 넘버 :  2275\n",
      "저장된 프레임 넘버 :  2300\n",
      "저장된 프레임 넘버 :  2325\n",
      "저장된 프레임 넘버 :  2350\n",
      "저장된 프레임 넘버 :  2375\n",
      "저장된 프레임 넘버 :  2400\n",
      "저장된 프레임 넘버 :  2425\n",
      "저장된 프레임 넘버 :  2450\n",
      "저장된 프레임 넘버 :  2475\n",
      "저장된 프레임 넘버 :  2500\n",
      "저장된 프레임 넘버 :  2525\n",
      "저장된 프레임 넘버 :  2550\n",
      "저장된 프레임 넘버 :  2575\n",
      "저장된 프레임 넘버 :  2600\n",
      "저장된 프레임 넘버 :  2625\n",
      "저장된 프레임 넘버 :  2650\n",
      "저장된 프레임 넘버 :  2675\n",
      "저장된 프레임 넘버 :  2700\n",
      "저장된 프레임 넘버 :  2725\n",
      "저장된 프레임 넘버 :  2750\n",
      "저장된 프레임 넘버 :  2775\n",
      "저장된 프레임 넘버 :  2800\n",
      "저장된 프레임 넘버 :  2825\n",
      "저장된 프레임 넘버 :  2850\n",
      "저장된 프레임 넘버 :  2875\n",
      "저장된 프레임 넘버 :  2900\n",
      "저장된 프레임 넘버 :  2925\n",
      "저장된 프레임 넘버 :  2950\n",
      "저장된 프레임 넘버 :  2975\n",
      "저장된 프레임 넘버 :  3000\n",
      "저장된 프레임 넘버 :  3025\n",
      "저장된 프레임 넘버 :  3050\n",
      "저장된 프레임 넘버 :  3075\n",
      "저장된 프레임 넘버 :  3100\n",
      "저장된 프레임 넘버 :  3125\n",
      "저장된 프레임 넘버 :  3150\n",
      "저장된 프레임 넘버 :  3175\n",
      "저장된 프레임 넘버 :  3200\n",
      "저장된 프레임 넘버 :  3225\n",
      "저장된 프레임 넘버 :  3250\n",
      "저장된 프레임 넘버 :  3275\n",
      "저장된 프레임 넘버 :  3300\n",
      "저장된 프레임 넘버 :  3325\n",
      "저장된 프레임 넘버 :  3350\n",
      "저장된 프레임 넘버 :  3375\n",
      "저장된 프레임 넘버 :  3400\n",
      "저장된 프레임 넘버 :  3425\n",
      "저장된 프레임 넘버 :  3450\n",
      "저장된 프레임 넘버 :  3475\n",
      "저장된 프레임 넘버 :  3500\n",
      "저장된 프레임 넘버 :  3525\n",
      "저장된 프레임 넘버 :  3550\n",
      "저장된 프레임 넘버 :  3575\n",
      "저장된 프레임 넘버 :  3600\n",
      "저장된 프레임 넘버 :  3625\n",
      "저장된 프레임 넘버 :  3650\n",
      "저장된 프레임 넘버 :  3675\n",
      "저장된 프레임 넘버 :  3700\n",
      "저장된 프레임 넘버 :  3725\n",
      "저장된 프레임 넘버 :  3750\n",
      "저장된 프레임 넘버 :  3775\n",
      "저장된 프레임 넘버 :  3800\n",
      "저장된 프레임 넘버 :  3825\n",
      "저장된 프레임 넘버 :  3850\n",
      "저장된 프레임 넘버 :  3875\n",
      "저장된 프레임 넘버 :  3900\n",
      "저장된 프레임 넘버 :  3925\n",
      "저장된 프레임 넘버 :  3950\n",
      "저장된 프레임 넘버 :  3975\n",
      "저장된 프레임 넘버 :  4000\n",
      "저장된 프레임 넘버 :  4025\n",
      "저장된 프레임 넘버 :  4050\n",
      "저장된 프레임 넘버 :  4075\n",
      "저장된 프레임 넘버 :  4100\n",
      "저장된 프레임 넘버 :  4125\n",
      "저장된 프레임 넘버 :  4150\n",
      "저장된 프레임 넘버 :  4175\n",
      "저장된 프레임 넘버 :  4200\n",
      "저장된 프레임 넘버 :  4225\n",
      "저장된 프레임 넘버 :  4250\n",
      "저장된 프레임 넘버 :  4275\n",
      "저장된 프레임 넘버 :  4300\n",
      "저장된 프레임 넘버 :  4325\n",
      "저장된 프레임 넘버 :  4350\n",
      "저장된 프레임 넘버 :  4375\n",
      "저장된 프레임 넘버 :  4400\n",
      "저장된 프레임 넘버 :  4425\n",
      "저장된 프레임 넘버 :  4450\n",
      "저장된 프레임 넘버 :  4475\n",
      "저장된 프레임 넘버 :  4500\n",
      "저장된 프레임 넘버 :  4525\n",
      "저장된 프레임 넘버 :  4550\n",
      "저장된 프레임 넘버 :  4575\n",
      "저장된 프레임 넘버 :  4600\n",
      "저장된 프레임 넘버 :  4625\n",
      "저장된 프레임 넘버 :  4650\n",
      "저장된 프레임 넘버 :  4675\n",
      "저장된 프레임 넘버 :  4700\n",
      "저장된 프레임 넘버 :  4725\n",
      "저장된 프레임 넘버 :  4750\n",
      "저장된 프레임 넘버 :  4775\n",
      "저장된 프레임 넘버 :  4800\n",
      "저장된 프레임 넘버 :  4825\n",
      "저장된 프레임 넘버 :  4850\n",
      "저장된 프레임 넘버 :  4875\n",
      "저장된 프레임 넘버 :  4900\n",
      "저장된 프레임 넘버 :  4925\n",
      "저장된 프레임 넘버 :  4950\n",
      "저장된 프레임 넘버 :  4975\n",
      "저장된 프레임 넘버 :  5000\n",
      "저장된 프레임 넘버 :  5025\n",
      "저장된 프레임 넘버 :  5050\n",
      "저장된 프레임 넘버 :  5075\n",
      "저장된 프레임 넘버 :  5100\n",
      "저장된 프레임 넘버 :  5125\n",
      "저장된 프레임 넘버 :  5150\n",
      "저장된 프레임 넘버 :  5175\n",
      "저장된 프레임 넘버 :  5200\n",
      "저장된 프레임 넘버 :  5225\n",
      "저장된 프레임 넘버 :  5250\n",
      "저장된 프레임 넘버 :  5275\n",
      "저장된 프레임 넘버 :  5300\n",
      "저장된 프레임 넘버 :  5325\n",
      "저장된 프레임 넘버 :  5350\n",
      "저장된 프레임 넘버 :  5375\n",
      "저장된 프레임 넘버 :  5400\n",
      "저장된 프레임 넘버 :  5425\n",
      "저장된 프레임 넘버 :  5450\n",
      "저장된 프레임 넘버 :  5475\n",
      "저장된 프레임 넘버 :  5500\n",
      "저장된 프레임 넘버 :  5525\n",
      "저장된 프레임 넘버 :  5550\n",
      "저장된 프레임 넘버 :  5575\n",
      "저장된 프레임 넘버 :  5600\n",
      "저장된 프레임 넘버 :  5625\n",
      "저장된 프레임 넘버 :  5650\n",
      "저장된 프레임 넘버 :  5675\n",
      "저장된 프레임 넘버 :  5700\n",
      "저장된 프레임 넘버 :  5725\n",
      "저장된 프레임 넘버 :  5750\n",
      "저장된 프레임 넘버 :  5775\n",
      "저장된 프레임 넘버 :  5800\n",
      "저장된 프레임 넘버 :  5825\n",
      "저장된 프레임 넘버 :  5850\n",
      "저장된 프레임 넘버 :  5875\n",
      "저장된 프레임 넘버 :  5900\n",
      "저장된 프레임 넘버 :  5925\n",
      "저장된 프레임 넘버 :  5950\n",
      "저장된 프레임 넘버 :  5975\n",
      "저장된 프레임 넘버 :  6000\n",
      "저장된 프레임 넘버 :  6025\n",
      "저장된 프레임 넘버 :  6050\n",
      "저장된 프레임 넘버 :  6075\n",
      "저장된 프레임 넘버 :  6100\n",
      "저장된 프레임 넘버 :  6125\n",
      "저장된 프레임 넘버 :  6150\n",
      "저장된 프레임 넘버 :  6175\n",
      "저장된 프레임 넘버 :  6200\n",
      "저장된 프레임 넘버 :  6225\n",
      "저장된 프레임 넘버 :  6250\n",
      "저장된 프레임 넘버 :  6275\n",
      "저장된 프레임 넘버 :  6300\n",
      "저장된 프레임 넘버 :  6325\n",
      "저장된 프레임 넘버 :  6350\n",
      "저장된 프레임 넘버 :  6375\n",
      "저장된 프레임 넘버 :  6400\n",
      "저장된 프레임 넘버 :  6425\n",
      "저장된 프레임 넘버 :  6450\n",
      "저장된 프레임 넘버 :  6475\n",
      "저장된 프레임 넘버 :  6500\n",
      "저장된 프레임 넘버 :  6525\n",
      "저장된 프레임 넘버 :  6550\n",
      "저장된 프레임 넘버 :  6575\n",
      "저장된 프레임 넘버 :  6600\n",
      "저장된 프레임 넘버 :  6625\n",
      "저장된 프레임 넘버 :  6650\n",
      "저장된 프레임 넘버 :  6675\n",
      "저장된 프레임 넘버 :  6700\n",
      "저장된 프레임 넘버 :  6725\n",
      "저장된 프레임 넘버 :  6750\n",
      "저장된 프레임 넘버 :  6775\n",
      "저장된 프레임 넘버 :  6800\n",
      "저장된 프레임 넘버 :  6825\n",
      "저장된 프레임 넘버 :  6850\n",
      "저장된 프레임 넘버 :  6875\n",
      "저장된 프레임 넘버 :  6900\n",
      "저장된 프레임 넘버 :  6925\n",
      "저장된 프레임 넘버 :  6950\n",
      "저장된 프레임 넘버 :  6975\n",
      "저장된 프레임 넘버 :  7000\n",
      "저장된 프레임 넘버 :  7025\n",
      "저장된 프레임 넘버 :  7050\n",
      "저장된 프레임 넘버 :  7075\n",
      "저장된 프레임 넘버 :  7100\n",
      "저장된 프레임 넘버 :  7125\n",
      "저장된 프레임 넘버 :  7150\n",
      "저장된 프레임 넘버 :  7175\n",
      "저장된 프레임 넘버 :  7200\n",
      "저장된 프레임 넘버 :  7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  60%|██████    | 3/5 [01:35<01:02, 31.24s/item]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 프레임 넘버 :  7250\n",
      "저장된 프레임 넘버 :  7275\n",
      "full_path :  /home/seongmin/src/Python_WS/data/electric_tunnel/20230719_155613.mp4\n",
      "file_name :  20230719_155613\n",
      "======== 로드할 비디오 경로 :  /home/seongmin/src/Python_WS/data/electric_tunnel/20230719_155613.mp4\n",
      "저장된 프레임 넘버 :  25\n",
      "저장된 프레임 넘버 :  50\n",
      "저장된 프레임 넘버 :  75\n",
      "저장된 프레임 넘버 :  100\n",
      "저장된 프레임 넘버 :  125\n",
      "저장된 프레임 넘버 :  150\n",
      "저장된 프레임 넘버 :  175\n",
      "저장된 프레임 넘버 :  200\n",
      "저장된 프레임 넘버 :  225\n",
      "저장된 프레임 넘버 :  250\n",
      "저장된 프레임 넘버 :  275\n",
      "저장된 프레임 넘버 :  300\n",
      "저장된 프레임 넘버 :  325\n",
      "저장된 프레임 넘버 :  350\n",
      "저장된 프레임 넘버 :  375\n",
      "저장된 프레임 넘버 :  400\n",
      "저장된 프레임 넘버 :  425\n",
      "저장된 프레임 넘버 :  450\n",
      "저장된 프레임 넘버 :  475\n",
      "저장된 프레임 넘버 :  500\n",
      "저장된 프레임 넘버 :  525\n",
      "저장된 프레임 넘버 :  550\n",
      "저장된 프레임 넘버 :  575\n",
      "저장된 프레임 넘버 :  600\n",
      "저장된 프레임 넘버 :  625\n",
      "저장된 프레임 넘버 :  650\n",
      "저장된 프레임 넘버 :  675\n",
      "저장된 프레임 넘버 :  700\n",
      "저장된 프레임 넘버 :  725\n",
      "저장된 프레임 넘버 :  750\n",
      "저장된 프레임 넘버 :  775\n",
      "저장된 프레임 넘버 :  800\n",
      "저장된 프레임 넘버 :  825\n",
      "저장된 프레임 넘버 :  850\n",
      "저장된 프레임 넘버 :  875\n",
      "저장된 프레임 넘버 :  900\n",
      "저장된 프레임 넘버 :  925\n",
      "저장된 프레임 넘버 :  950\n",
      "저장된 프레임 넘버 :  975\n",
      "저장된 프레임 넘버 :  1000\n",
      "저장된 프레임 넘버 :  1025\n",
      "저장된 프레임 넘버 :  1050\n",
      "저장된 프레임 넘버 :  1075\n",
      "저장된 프레임 넘버 :  1100\n",
      "저장된 프레임 넘버 :  1125\n",
      "저장된 프레임 넘버 :  1150\n",
      "저장된 프레임 넘버 :  1175\n",
      "저장된 프레임 넘버 :  1200\n",
      "저장된 프레임 넘버 :  1225\n",
      "저장된 프레임 넘버 :  1250\n",
      "저장된 프레임 넘버 :  1275\n",
      "저장된 프레임 넘버 :  1300\n",
      "저장된 프레임 넘버 :  1325\n",
      "저장된 프레임 넘버 :  1350\n",
      "저장된 프레임 넘버 :  1375\n",
      "저장된 프레임 넘버 :  1400\n",
      "저장된 프레임 넘버 :  1425\n",
      "저장된 프레임 넘버 :  1450\n",
      "저장된 프레임 넘버 :  1475\n",
      "저장된 프레임 넘버 :  1500\n",
      "저장된 프레임 넘버 :  1525\n",
      "저장된 프레임 넘버 :  1550\n",
      "저장된 프레임 넘버 :  1575\n",
      "저장된 프레임 넘버 :  1600\n",
      "저장된 프레임 넘버 :  1625\n",
      "저장된 프레임 넘버 :  1650\n",
      "저장된 프레임 넘버 :  1675\n",
      "저장된 프레임 넘버 :  1700\n",
      "저장된 프레임 넘버 :  1725\n",
      "저장된 프레임 넘버 :  1750\n",
      "저장된 프레임 넘버 :  1775\n",
      "저장된 프레임 넘버 :  1800\n",
      "저장된 프레임 넘버 :  1825\n",
      "저장된 프레임 넘버 :  1850\n",
      "저장된 프레임 넘버 :  1875\n",
      "저장된 프레임 넘버 :  1900\n",
      "저장된 프레임 넘버 :  1925\n",
      "저장된 프레임 넘버 :  1950\n",
      "저장된 프레임 넘버 :  1975\n",
      "저장된 프레임 넘버 :  2000\n",
      "저장된 프레임 넘버 :  2025\n",
      "저장된 프레임 넘버 :  2050\n",
      "저장된 프레임 넘버 :  2075\n",
      "저장된 프레임 넘버 :  2100\n",
      "저장된 프레임 넘버 :  2125\n",
      "저장된 프레임 넘버 :  2150\n",
      "저장된 프레임 넘버 :  2175\n",
      "저장된 프레임 넘버 :  2200\n",
      "저장된 프레임 넘버 :  2225\n",
      "저장된 프레임 넘버 :  2250\n",
      "저장된 프레임 넘버 :  2275\n",
      "저장된 프레임 넘버 :  2300\n",
      "저장된 프레임 넘버 :  2325\n",
      "저장된 프레임 넘버 :  2350\n",
      "저장된 프레임 넘버 :  2375\n",
      "저장된 프레임 넘버 :  2400\n",
      "저장된 프레임 넘버 :  2425\n",
      "저장된 프레임 넘버 :  2450\n",
      "저장된 프레임 넘버 :  2475\n",
      "저장된 프레임 넘버 :  2500\n",
      "저장된 프레임 넘버 :  2525\n",
      "저장된 프레임 넘버 :  2550\n",
      "저장된 프레임 넘버 :  2575\n",
      "저장된 프레임 넘버 :  2600\n",
      "저장된 프레임 넘버 :  2625\n",
      "저장된 프레임 넘버 :  2650\n",
      "저장된 프레임 넘버 :  2675\n",
      "저장된 프레임 넘버 :  2700\n",
      "저장된 프레임 넘버 :  2725\n",
      "저장된 프레임 넘버 :  2750\n",
      "저장된 프레임 넘버 :  2775\n",
      "저장된 프레임 넘버 :  2800\n",
      "저장된 프레임 넘버 :  2825\n",
      "저장된 프레임 넘버 :  2850\n",
      "저장된 프레임 넘버 :  2875\n",
      "저장된 프레임 넘버 :  2900\n",
      "저장된 프레임 넘버 :  2925\n",
      "저장된 프레임 넘버 :  2950\n",
      "저장된 프레임 넘버 :  2975\n",
      "저장된 프레임 넘버 :  3000\n",
      "저장된 프레임 넘버 :  3025\n",
      "저장된 프레임 넘버 :  3050\n",
      "저장된 프레임 넘버 :  3075\n",
      "저장된 프레임 넘버 :  3100\n",
      "저장된 프레임 넘버 :  3125\n",
      "저장된 프레임 넘버 :  3150\n",
      "저장된 프레임 넘버 :  3175\n",
      "저장된 프레임 넘버 :  3200\n",
      "저장된 프레임 넘버 :  3225\n",
      "저장된 프레임 넘버 :  3250\n",
      "저장된 프레임 넘버 :  3275\n",
      "저장된 프레임 넘버 :  3300\n",
      "저장된 프레임 넘버 :  3325\n",
      "저장된 프레임 넘버 :  3350\n",
      "저장된 프레임 넘버 :  3375\n",
      "저장된 프레임 넘버 :  3400\n",
      "저장된 프레임 넘버 :  3425\n",
      "저장된 프레임 넘버 :  3450\n",
      "저장된 프레임 넘버 :  3475\n",
      "저장된 프레임 넘버 :  3500\n",
      "저장된 프레임 넘버 :  3525\n",
      "저장된 프레임 넘버 :  3550\n",
      "저장된 프레임 넘버 :  3575\n",
      "저장된 프레임 넘버 :  3600\n",
      "저장된 프레임 넘버 :  3625\n",
      "저장된 프레임 넘버 :  3650\n",
      "저장된 프레임 넘버 :  3675\n",
      "저장된 프레임 넘버 :  3700\n",
      "저장된 프레임 넘버 :  3725\n",
      "저장된 프레임 넘버 :  3750\n",
      "저장된 프레임 넘버 :  3775\n",
      "저장된 프레임 넘버 :  3800\n",
      "저장된 프레임 넘버 :  3825\n",
      "저장된 프레임 넘버 :  3850\n",
      "저장된 프레임 넘버 :  3875\n",
      "저장된 프레임 넘버 :  3900\n",
      "저장된 프레임 넘버 :  3925\n",
      "저장된 프레임 넘버 :  3950\n",
      "저장된 프레임 넘버 :  3975\n",
      "저장된 프레임 넘버 :  4000\n",
      "저장된 프레임 넘버 :  4025\n",
      "저장된 프레임 넘버 :  4050\n",
      "저장된 프레임 넘버 :  4075\n",
      "저장된 프레임 넘버 :  4100\n",
      "저장된 프레임 넘버 :  4125\n",
      "저장된 프레임 넘버 :  4150\n",
      "저장된 프레임 넘버 :  4175\n",
      "저장된 프레임 넘버 :  4200\n",
      "저장된 프레임 넘버 :  4225\n",
      "저장된 프레임 넘버 :  4250\n",
      "저장된 프레임 넘버 :  4275\n",
      "저장된 프레임 넘버 :  4300\n",
      "저장된 프레임 넘버 :  4325\n",
      "저장된 프레임 넘버 :  4350\n",
      "저장된 프레임 넘버 :  4375\n",
      "저장된 프레임 넘버 :  4400\n",
      "저장된 프레임 넘버 :  4425\n",
      "저장된 프레임 넘버 :  4450\n",
      "저장된 프레임 넘버 :  4475\n",
      "저장된 프레임 넘버 :  4500\n",
      "저장된 프레임 넘버 :  4525\n",
      "저장된 프레임 넘버 :  4550\n",
      "저장된 프레임 넘버 :  4575\n",
      "저장된 프레임 넘버 :  4600\n",
      "저장된 프레임 넘버 :  4625\n",
      "저장된 프레임 넘버 :  4650\n",
      "저장된 프레임 넘버 :  4675\n",
      "저장된 프레임 넘버 :  4700\n",
      "저장된 프레임 넘버 :  4725\n",
      "저장된 프레임 넘버 :  4750\n",
      "저장된 프레임 넘버 :  4775\n",
      "저장된 프레임 넘버 :  4800\n",
      "저장된 프레임 넘버 :  4825\n",
      "저장된 프레임 넘버 :  4850\n",
      "저장된 프레임 넘버 :  4875\n",
      "저장된 프레임 넘버 :  4900\n",
      "저장된 프레임 넘버 :  4925\n",
      "저장된 프레임 넘버 :  4950\n",
      "저장된 프레임 넘버 :  4975\n",
      "저장된 프레임 넘버 :  5000\n",
      "저장된 프레임 넘버 :  5025\n",
      "저장된 프레임 넘버 :  5050\n",
      "저장된 프레임 넘버 :  5075\n",
      "저장된 프레임 넘버 :  5100\n",
      "저장된 프레임 넘버 :  5125\n",
      "저장된 프레임 넘버 :  5150\n",
      "저장된 프레임 넘버 :  5175\n",
      "저장된 프레임 넘버 :  5200\n",
      "저장된 프레임 넘버 :  5225\n",
      "저장된 프레임 넘버 :  5250\n",
      "저장된 프레임 넘버 :  5275\n",
      "저장된 프레임 넘버 :  5300\n",
      "저장된 프레임 넘버 :  5325\n",
      "저장된 프레임 넘버 :  5350\n",
      "저장된 프레임 넘버 :  5375\n",
      "저장된 프레임 넘버 :  5400\n",
      "저장된 프레임 넘버 :  5425\n",
      "저장된 프레임 넘버 :  5450\n",
      "저장된 프레임 넘버 :  5475\n",
      "저장된 프레임 넘버 :  5500\n",
      "저장된 프레임 넘버 :  5525\n",
      "저장된 프레임 넘버 :  5550\n",
      "저장된 프레임 넘버 :  5575\n",
      "저장된 프레임 넘버 :  5600\n",
      "저장된 프레임 넘버 :  5625\n",
      "저장된 프레임 넘버 :  5650\n",
      "저장된 프레임 넘버 :  5675\n",
      "저장된 프레임 넘버 :  5700\n",
      "저장된 프레임 넘버 :  5725\n",
      "저장된 프레임 넘버 :  5750\n",
      "저장된 프레임 넘버 :  5775\n",
      "저장된 프레임 넘버 :  5800\n",
      "저장된 프레임 넘버 :  5825\n",
      "저장된 프레임 넘버 :  5850\n",
      "저장된 프레임 넘버 :  5875\n",
      "저장된 프레임 넘버 :  5900\n",
      "저장된 프레임 넘버 :  5925\n",
      "저장된 프레임 넘버 :  5950\n",
      "저장된 프레임 넘버 :  5975\n",
      "저장된 프레임 넘버 :  6000\n",
      "저장된 프레임 넘버 :  6025\n",
      "저장된 프레임 넘버 :  6050\n",
      "저장된 프레임 넘버 :  6075\n",
      "저장된 프레임 넘버 :  6100\n",
      "저장된 프레임 넘버 :  6125\n",
      "저장된 프레임 넘버 :  6150\n",
      "저장된 프레임 넘버 :  6175\n",
      "저장된 프레임 넘버 :  6200\n",
      "저장된 프레임 넘버 :  6225\n",
      "저장된 프레임 넘버 :  6250\n",
      "저장된 프레임 넘버 :  6275\n",
      "저장된 프레임 넘버 :  6300\n",
      "저장된 프레임 넘버 :  6325\n",
      "저장된 프레임 넘버 :  6350\n",
      "저장된 프레임 넘버 :  6375\n",
      "저장된 프레임 넘버 :  6400\n",
      "저장된 프레임 넘버 :  6425\n",
      "저장된 프레임 넘버 :  6450\n",
      "저장된 프레임 넘버 :  6475\n",
      "저장된 프레임 넘버 :  6500\n",
      "저장된 프레임 넘버 :  6525\n",
      "저장된 프레임 넘버 :  6550\n",
      "저장된 프레임 넘버 :  6575\n",
      "저장된 프레임 넘버 :  6600\n",
      "저장된 프레임 넘버 :  6625\n",
      "저장된 프레임 넘버 :  6650\n",
      "저장된 프레임 넘버 :  6675\n",
      "저장된 프레임 넘버 :  6700\n",
      "저장된 프레임 넘버 :  6725\n",
      "저장된 프레임 넘버 :  6750\n",
      "저장된 프레임 넘버 :  6775\n",
      "저장된 프레임 넘버 :  6800\n",
      "저장된 프레임 넘버 :  6825\n",
      "저장된 프레임 넘버 :  6850\n",
      "저장된 프레임 넘버 :  6875\n",
      "저장된 프레임 넘버 :  6900\n",
      "저장된 프레임 넘버 :  6925\n",
      "저장된 프레임 넘버 :  6950\n",
      "저장된 프레임 넘버 :  6975\n",
      "저장된 프레임 넘버 :  7000\n",
      "저장된 프레임 넘버 :  7025\n",
      "저장된 프레임 넘버 :  7050\n",
      "저장된 프레임 넘버 :  7075\n",
      "저장된 프레임 넘버 :  7100\n",
      "저장된 프레임 넘버 :  7125\n",
      "저장된 프레임 넘버 :  7150\n",
      "저장된 프레임 넘버 :  7175\n",
      "저장된 프레임 넘버 :  7200\n",
      "저장된 프레임 넘버 :  7225\n",
      "저장된 프레임 넘버 :  7250\n",
      "저장된 프레임 넘버 :  7275\n",
      "저장된 프레임 넘버 :  7300\n",
      "저장된 프레임 넘버 :  7325\n",
      "저장된 프레임 넘버 :  7350\n",
      "저장된 프레임 넘버 :  7375\n",
      "저장된 프레임 넘버 :  7400\n",
      "저장된 프레임 넘버 :  7425\n",
      "저장된 프레임 넘버 :  7450\n",
      "저장된 프레임 넘버 :  7475\n",
      "저장된 프레임 넘버 :  7500\n",
      "저장된 프레임 넘버 :  7525\n",
      "저장된 프레임 넘버 :  7550\n",
      "저장된 프레임 넘버 :  7575\n",
      "저장된 프레임 넘버 :  7600\n",
      "저장된 프레임 넘버 :  7625\n",
      "저장된 프레임 넘버 :  7650\n",
      "저장된 프레임 넘버 :  7675\n",
      "저장된 프레임 넘버 :  7700\n",
      "저장된 프레임 넘버 :  7725\n",
      "저장된 프레임 넘버 :  7750\n",
      "저장된 프레임 넘버 :  7775\n",
      "저장된 프레임 넘버 :  7800\n",
      "저장된 프레임 넘버 :  7825\n",
      "저장된 프레임 넘버 :  7850\n",
      "저장된 프레임 넘버 :  7875\n",
      "저장된 프레임 넘버 :  7900\n",
      "저장된 프레임 넘버 :  7925\n",
      "저장된 프레임 넘버 :  7950\n",
      "저장된 프레임 넘버 :  7975\n",
      "저장된 프레임 넘버 :  8000\n",
      "저장된 프레임 넘버 :  8025\n",
      "저장된 프레임 넘버 :  8050\n",
      "저장된 프레임 넘버 :  8075\n",
      "저장된 프레임 넘버 :  8100\n",
      "저장된 프레임 넘버 :  8125\n",
      "저장된 프레임 넘버 :  8150\n",
      "저장된 프레임 넘버 :  8175\n",
      "저장된 프레임 넘버 :  8200\n",
      "저장된 프레임 넘버 :  8225\n",
      "저장된 프레임 넘버 :  8250\n",
      "저장된 프레임 넘버 :  8275\n",
      "저장된 프레임 넘버 :  8300\n",
      "저장된 프레임 넘버 :  8325\n",
      "저장된 프레임 넘버 :  8350\n",
      "저장된 프레임 넘버 :  8375\n",
      "저장된 프레임 넘버 :  8400\n",
      "저장된 프레임 넘버 :  8425\n",
      "저장된 프레임 넘버 :  8450\n",
      "저장된 프레임 넘버 :  8475\n",
      "저장된 프레임 넘버 :  8500\n",
      "저장된 프레임 넘버 :  8525\n",
      "저장된 프레임 넘버 :  8550\n",
      "저장된 프레임 넘버 :  8575\n",
      "저장된 프레임 넘버 :  8600\n",
      "저장된 프레임 넘버 :  8625\n",
      "저장된 프레임 넘버 :  8650\n",
      "저장된 프레임 넘버 :  8675\n",
      "저장된 프레임 넘버 :  8700\n",
      "저장된 프레임 넘버 :  8725\n",
      "저장된 프레임 넘버 :  8750\n",
      "저장된 프레임 넘버 :  8775\n",
      "저장된 프레임 넘버 :  8800\n",
      "저장된 프레임 넘버 :  8825\n",
      "저장된 프레임 넘버 :  8850\n",
      "저장된 프레임 넘버 :  8875\n",
      "저장된 프레임 넘버 :  8900\n",
      "저장된 프레임 넘버 :  8925\n",
      "저장된 프레임 넘버 :  8950\n",
      "저장된 프레임 넘버 :  8975\n",
      "저장된 프레임 넘버 :  9000\n",
      "저장된 프레임 넘버 :  9025\n",
      "저장된 프레임 넘버 :  9050\n",
      "저장된 프레임 넘버 :  9075\n",
      "저장된 프레임 넘버 :  9100\n",
      "저장된 프레임 넘버 :  9125\n",
      "저장된 프레임 넘버 :  9150\n",
      "저장된 프레임 넘버 :  9175\n",
      "저장된 프레임 넘버 :  9200\n",
      "저장된 프레임 넘버 :  9225\n",
      "저장된 프레임 넘버 :  9250\n",
      "저장된 프레임 넘버 :  9275\n",
      "저장된 프레임 넘버 :  9300\n",
      "저장된 프레임 넘버 :  9325\n",
      "저장된 프레임 넘버 :  9350\n",
      "저장된 프레임 넘버 :  9375\n",
      "저장된 프레임 넘버 :  9400\n",
      "저장된 프레임 넘버 :  9425\n",
      "저장된 프레임 넘버 :  9450\n",
      "저장된 프레임 넘버 :  9475\n",
      "저장된 프레임 넘버 :  9500\n",
      "저장된 프레임 넘버 :  9525\n",
      "저장된 프레임 넘버 :  9550\n",
      "저장된 프레임 넘버 :  9575\n",
      "저장된 프레임 넘버 :  9600\n",
      "저장된 프레임 넘버 :  9625\n",
      "저장된 프레임 넘버 :  9650\n",
      "저장된 프레임 넘버 :  9675\n",
      "저장된 프레임 넘버 :  9700\n",
      "저장된 프레임 넘버 :  9725\n",
      "저장된 프레임 넘버 :  9750\n",
      "저장된 프레임 넘버 :  9775\n",
      "저장된 프레임 넘버 :  9800\n",
      "저장된 프레임 넘버 :  9825\n",
      "저장된 프레임 넘버 :  9850\n",
      "저장된 프레임 넘버 :  9875\n",
      "저장된 프레임 넘버 :  9900\n",
      "저장된 프레임 넘버 :  9925\n",
      "저장된 프레임 넘버 :  9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  80%|████████  | 4/5 [02:14<00:34, 34.35s/item]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_path :  /home/seongmin/src/Python_WS/data/electric_tunnel/20230719_161105.mp4\n",
      "file_name :  20230719_161105\n",
      "======== 로드할 비디오 경로 :  /home/seongmin/src/Python_WS/data/electric_tunnel/20230719_161105.mp4\n",
      "저장된 프레임 넘버 :  25\n",
      "저장된 프레임 넘버 :  50\n",
      "저장된 프레임 넘버 :  75\n",
      "저장된 프레임 넘버 :  100\n",
      "저장된 프레임 넘버 :  125\n",
      "저장된 프레임 넘버 :  150\n",
      "저장된 프레임 넘버 :  175\n",
      "저장된 프레임 넘버 :  200\n",
      "저장된 프레임 넘버 :  225\n",
      "저장된 프레임 넘버 :  250\n",
      "저장된 프레임 넘버 :  275\n",
      "저장된 프레임 넘버 :  300\n",
      "저장된 프레임 넘버 :  325\n",
      "저장된 프레임 넘버 :  350\n",
      "저장된 프레임 넘버 :  375\n",
      "저장된 프레임 넘버 :  400\n",
      "저장된 프레임 넘버 :  425\n",
      "저장된 프레임 넘버 :  450\n",
      "저장된 프레임 넘버 :  475\n",
      "저장된 프레임 넘버 :  500\n",
      "저장된 프레임 넘버 :  525\n",
      "저장된 프레임 넘버 :  550\n",
      "저장된 프레임 넘버 :  575\n",
      "저장된 프레임 넘버 :  600\n",
      "저장된 프레임 넘버 :  625\n",
      "저장된 프레임 넘버 :  650\n",
      "저장된 프레임 넘버 :  675\n",
      "저장된 프레임 넘버 :  700\n",
      "저장된 프레임 넘버 :  725\n",
      "저장된 프레임 넘버 :  750\n",
      "저장된 프레임 넘버 :  775\n",
      "저장된 프레임 넘버 :  800\n",
      "저장된 프레임 넘버 :  825\n",
      "저장된 프레임 넘버 :  850\n",
      "저장된 프레임 넘버 :  875\n",
      "저장된 프레임 넘버 :  900\n",
      "저장된 프레임 넘버 :  925\n",
      "저장된 프레임 넘버 :  950\n",
      "저장된 프레임 넘버 :  975\n",
      "저장된 프레임 넘버 :  1000\n",
      "저장된 프레임 넘버 :  1025\n",
      "저장된 프레임 넘버 :  1050\n",
      "저장된 프레임 넘버 :  1075\n",
      "저장된 프레임 넘버 :  1100\n",
      "저장된 프레임 넘버 :  1125\n",
      "저장된 프레임 넘버 :  1150\n",
      "저장된 프레임 넘버 :  1175\n",
      "저장된 프레임 넘버 :  1200\n",
      "저장된 프레임 넘버 :  1225\n",
      "저장된 프레임 넘버 :  1250\n",
      "저장된 프레임 넘버 :  1275\n",
      "저장된 프레임 넘버 :  1300\n",
      "저장된 프레임 넘버 :  1325\n",
      "저장된 프레임 넘버 :  1350\n",
      "저장된 프레임 넘버 :  1375\n",
      "저장된 프레임 넘버 :  1400\n",
      "저장된 프레임 넘버 :  1425\n",
      "저장된 프레임 넘버 :  1450\n",
      "저장된 프레임 넘버 :  1475\n",
      "저장된 프레임 넘버 :  1500\n",
      "저장된 프레임 넘버 :  1525\n",
      "저장된 프레임 넘버 :  1550\n",
      "저장된 프레임 넘버 :  1575\n",
      "저장된 프레임 넘버 :  1600\n",
      "저장된 프레임 넘버 :  1625\n",
      "저장된 프레임 넘버 :  1650\n",
      "저장된 프레임 넘버 :  1675\n",
      "저장된 프레임 넘버 :  1700\n",
      "저장된 프레임 넘버 :  1725\n",
      "저장된 프레임 넘버 :  1750\n",
      "저장된 프레임 넘버 :  1775\n",
      "저장된 프레임 넘버 :  1800\n",
      "저장된 프레임 넘버 :  1825\n",
      "저장된 프레임 넘버 :  1850\n",
      "저장된 프레임 넘버 :  1875\n",
      "저장된 프레임 넘버 :  1900\n",
      "저장된 프레임 넘버 :  1925\n",
      "저장된 프레임 넘버 :  1950\n",
      "저장된 프레임 넘버 :  1975\n",
      "저장된 프레임 넘버 :  2000\n",
      "저장된 프레임 넘버 :  2025\n",
      "저장된 프레임 넘버 :  2050\n",
      "저장된 프레임 넘버 :  2075\n",
      "저장된 프레임 넘버 :  2100\n",
      "저장된 프레임 넘버 :  2125\n",
      "저장된 프레임 넘버 :  2150\n",
      "저장된 프레임 넘버 :  2175\n",
      "저장된 프레임 넘버 :  2200\n",
      "저장된 프레임 넘버 :  2225\n",
      "저장된 프레임 넘버 :  2250\n",
      "저장된 프레임 넘버 :  2275\n",
      "저장된 프레임 넘버 :  2300\n",
      "저장된 프레임 넘버 :  2325\n",
      "저장된 프레임 넘버 :  2350\n",
      "저장된 프레임 넘버 :  2375\n",
      "저장된 프레임 넘버 :  2400\n",
      "저장된 프레임 넘버 :  2425\n",
      "저장된 프레임 넘버 :  2450\n",
      "저장된 프레임 넘버 :  2475\n",
      "저장된 프레임 넘버 :  2500\n",
      "저장된 프레임 넘버 :  2525\n",
      "저장된 프레임 넘버 :  2550\n",
      "저장된 프레임 넘버 :  2575\n",
      "저장된 프레임 넘버 :  2600\n",
      "저장된 프레임 넘버 :  2625\n",
      "저장된 프레임 넘버 :  2650\n",
      "저장된 프레임 넘버 :  2675\n",
      "저장된 프레임 넘버 :  2700\n",
      "저장된 프레임 넘버 :  2725\n",
      "저장된 프레임 넘버 :  2750\n",
      "저장된 프레임 넘버 :  2775\n",
      "저장된 프레임 넘버 :  2800\n",
      "저장된 프레임 넘버 :  2825\n",
      "저장된 프레임 넘버 :  2850\n",
      "저장된 프레임 넘버 :  2875\n",
      "저장된 프레임 넘버 :  2900\n",
      "저장된 프레임 넘버 :  2925\n",
      "저장된 프레임 넘버 :  2950\n",
      "저장된 프레임 넘버 :  2975\n",
      "저장된 프레임 넘버 :  3000\n",
      "저장된 프레임 넘버 :  3025\n",
      "저장된 프레임 넘버 :  3050\n",
      "저장된 프레임 넘버 :  3075\n",
      "저장된 프레임 넘버 :  3100\n",
      "저장된 프레임 넘버 :  3125\n",
      "저장된 프레임 넘버 :  3150\n",
      "저장된 프레임 넘버 :  3175\n",
      "저장된 프레임 넘버 :  3200\n",
      "저장된 프레임 넘버 :  3225\n",
      "저장된 프레임 넘버 :  3250\n",
      "저장된 프레임 넘버 :  3275\n",
      "저장된 프레임 넘버 :  3300\n",
      "저장된 프레임 넘버 :  3325\n",
      "저장된 프레임 넘버 :  3350\n",
      "저장된 프레임 넘버 :  3375\n",
      "저장된 프레임 넘버 :  3400\n",
      "저장된 프레임 넘버 :  3425\n",
      "저장된 프레임 넘버 :  3450\n",
      "저장된 프레임 넘버 :  3475\n",
      "저장된 프레임 넘버 :  3500\n",
      "저장된 프레임 넘버 :  3525\n",
      "저장된 프레임 넘버 :  3550\n",
      "저장된 프레임 넘버 :  3575\n",
      "저장된 프레임 넘버 :  3600\n",
      "저장된 프레임 넘버 :  3625\n",
      "저장된 프레임 넘버 :  3650\n",
      "저장된 프레임 넘버 :  3675\n",
      "저장된 프레임 넘버 :  3700\n",
      "저장된 프레임 넘버 :  3725\n",
      "저장된 프레임 넘버 :  3750\n",
      "저장된 프레임 넘버 :  3775\n",
      "저장된 프레임 넘버 :  3800\n",
      "저장된 프레임 넘버 :  3825\n",
      "저장된 프레임 넘버 :  3850\n",
      "저장된 프레임 넘버 :  3875\n",
      "저장된 프레임 넘버 :  3900\n",
      "저장된 프레임 넘버 :  3925\n",
      "저장된 프레임 넘버 :  3950\n",
      "저장된 프레임 넘버 :  3975\n",
      "저장된 프레임 넘버 :  4000\n",
      "저장된 프레임 넘버 :  4025\n",
      "저장된 프레임 넘버 :  4050\n",
      "저장된 프레임 넘버 :  4075\n",
      "저장된 프레임 넘버 :  4100\n",
      "저장된 프레임 넘버 :  4125\n",
      "저장된 프레임 넘버 :  4150\n",
      "저장된 프레임 넘버 :  4175\n",
      "저장된 프레임 넘버 :  4200\n",
      "저장된 프레임 넘버 :  4225\n",
      "저장된 프레임 넘버 :  4250\n",
      "저장된 프레임 넘버 :  4275\n",
      "저장된 프레임 넘버 :  4300\n",
      "저장된 프레임 넘버 :  4325\n",
      "저장된 프레임 넘버 :  4350\n",
      "저장된 프레임 넘버 :  4375\n",
      "저장된 프레임 넘버 :  4400\n",
      "저장된 프레임 넘버 :  4425\n",
      "저장된 프레임 넘버 :  4450\n",
      "저장된 프레임 넘버 :  4475\n",
      "저장된 프레임 넘버 :  4500\n",
      "저장된 프레임 넘버 :  4525\n",
      "저장된 프레임 넘버 :  4550\n",
      "저장된 프레임 넘버 :  4575\n",
      "저장된 프레임 넘버 :  4600\n",
      "저장된 프레임 넘버 :  4625\n",
      "저장된 프레임 넘버 :  4650\n",
      "저장된 프레임 넘버 :  4675\n",
      "저장된 프레임 넘버 :  4700\n",
      "저장된 프레임 넘버 :  4725\n",
      "저장된 프레임 넘버 :  4750\n",
      "저장된 프레임 넘버 :  4775\n",
      "저장된 프레임 넘버 :  4800\n",
      "저장된 프레임 넘버 :  4825\n",
      "저장된 프레임 넘버 :  4850\n",
      "저장된 프레임 넘버 :  4875\n",
      "저장된 프레임 넘버 :  4900\n",
      "저장된 프레임 넘버 :  4925\n",
      "저장된 프레임 넘버 :  4950\n",
      "저장된 프레임 넘버 :  4975\n",
      "저장된 프레임 넘버 :  5000\n",
      "저장된 프레임 넘버 :  5025\n",
      "저장된 프레임 넘버 :  5050\n",
      "저장된 프레임 넘버 :  5075\n",
      "저장된 프레임 넘버 :  5100\n",
      "저장된 프레임 넘버 :  5125\n",
      "저장된 프레임 넘버 :  5150\n",
      "저장된 프레임 넘버 :  5175\n",
      "저장된 프레임 넘버 :  5200\n",
      "저장된 프레임 넘버 :  5225\n",
      "저장된 프레임 넘버 :  5250\n",
      "저장된 프레임 넘버 :  5275\n",
      "저장된 프레임 넘버 :  5300\n",
      "저장된 프레임 넘버 :  5325\n",
      "저장된 프레임 넘버 :  5350\n",
      "저장된 프레임 넘버 :  5375\n",
      "저장된 프레임 넘버 :  5400\n",
      "저장된 프레임 넘버 :  5425\n",
      "저장된 프레임 넘버 :  5450\n",
      "저장된 프레임 넘버 :  5475\n",
      "저장된 프레임 넘버 :  5500\n",
      "저장된 프레임 넘버 :  5525\n",
      "저장된 프레임 넘버 :  5550\n",
      "저장된 프레임 넘버 :  5575\n",
      "저장된 프레임 넘버 :  5600\n",
      "저장된 프레임 넘버 :  5625\n",
      "저장된 프레임 넘버 :  5650\n",
      "저장된 프레임 넘버 :  5675\n",
      "저장된 프레임 넘버 :  5700\n",
      "저장된 프레임 넘버 :  5725\n",
      "저장된 프레임 넘버 :  5750\n",
      "저장된 프레임 넘버 :  5775\n",
      "저장된 프레임 넘버 :  5800\n",
      "저장된 프레임 넘버 :  5825\n",
      "저장된 프레임 넘버 :  5850\n",
      "저장된 프레임 넘버 :  5875\n",
      "저장된 프레임 넘버 :  5900\n",
      "저장된 프레임 넘버 :  5925\n",
      "저장된 프레임 넘버 :  5950\n",
      "저장된 프레임 넘버 :  5975\n",
      "저장된 프레임 넘버 :  6000\n",
      "저장된 프레임 넘버 :  6025\n",
      "저장된 프레임 넘버 :  6050\n",
      "저장된 프레임 넘버 :  6075\n",
      "저장된 프레임 넘버 :  6100\n",
      "저장된 프레임 넘버 :  6125\n",
      "저장된 프레임 넘버 :  6150\n",
      "저장된 프레임 넘버 :  6175\n",
      "저장된 프레임 넘버 :  6200\n",
      "저장된 프레임 넘버 :  6225\n",
      "저장된 프레임 넘버 :  6250\n",
      "저장된 프레임 넘버 :  6275\n",
      "저장된 프레임 넘버 :  6300\n",
      "저장된 프레임 넘버 :  6325\n",
      "저장된 프레임 넘버 :  6350\n",
      "저장된 프레임 넘버 :  6375\n",
      "저장된 프레임 넘버 :  6400\n",
      "저장된 프레임 넘버 :  6425\n",
      "저장된 프레임 넘버 :  6450\n",
      "저장된 프레임 넘버 :  6475\n",
      "저장된 프레임 넘버 :  6500\n",
      "저장된 프레임 넘버 :  6525\n",
      "저장된 프레임 넘버 :  6550\n",
      "저장된 프레임 넘버 :  6575\n",
      "저장된 프레임 넘버 :  6600\n",
      "저장된 프레임 넘버 :  6625\n",
      "저장된 프레임 넘버 :  6650\n",
      "저장된 프레임 넘버 :  6675\n",
      "저장된 프레임 넘버 :  6700\n",
      "저장된 프레임 넘버 :  6725\n",
      "저장된 프레임 넘버 :  6750\n",
      "저장된 프레임 넘버 :  6775\n",
      "저장된 프레임 넘버 :  6800\n",
      "저장된 프레임 넘버 :  6825\n",
      "저장된 프레임 넘버 :  6850\n",
      "저장된 프레임 넘버 :  6875\n",
      "저장된 프레임 넘버 :  6900\n",
      "저장된 프레임 넘버 :  6925\n",
      "저장된 프레임 넘버 :  6950\n",
      "저장된 프레임 넘버 :  6975\n",
      "저장된 프레임 넘버 :  7000\n",
      "저장된 프레임 넘버 :  7025\n",
      "저장된 프레임 넘버 :  7050\n",
      "저장된 프레임 넘버 :  7075\n",
      "저장된 프레임 넘버 :  7100\n",
      "저장된 프레임 넘버 :  7125\n",
      "저장된 프레임 넘버 :  7150\n",
      "저장된 프레임 넘버 :  7175\n",
      "저장된 프레임 넘버 :  7200\n",
      "저장된 프레임 넘버 :  7225\n",
      "저장된 프레임 넘버 :  7250\n",
      "저장된 프레임 넘버 :  7275\n",
      "저장된 프레임 넘버 :  7300\n",
      "저장된 프레임 넘버 :  7325\n",
      "저장된 프레임 넘버 :  7350\n",
      "저장된 프레임 넘버 :  7375\n",
      "저장된 프레임 넘버 :  7400\n",
      "저장된 프레임 넘버 :  7425\n",
      "저장된 프레임 넘버 :  7450\n",
      "저장된 프레임 넘버 :  7475\n",
      "저장된 프레임 넘버 :  7500\n",
      "저장된 프레임 넘버 :  7525\n",
      "저장된 프레임 넘버 :  7550\n",
      "저장된 프레임 넘버 :  7575\n",
      "저장된 프레임 넘버 :  7600\n",
      "저장된 프레임 넘버 :  7625\n",
      "저장된 프레임 넘버 :  7650\n",
      "저장된 프레임 넘버 :  7675\n",
      "저장된 프레임 넘버 :  7700\n",
      "저장된 프레임 넘버 :  7725\n",
      "저장된 프레임 넘버 :  7750\n",
      "저장된 프레임 넘버 :  7775\n",
      "저장된 프레임 넘버 :  7800\n",
      "저장된 프레임 넘버 :  7825\n",
      "저장된 프레임 넘버 :  7850\n",
      "저장된 프레임 넘버 :  7875\n",
      "저장된 프레임 넘버 :  7900\n",
      "저장된 프레임 넘버 :  7925\n",
      "저장된 프레임 넘버 :  7950\n",
      "저장된 프레임 넘버 :  7975\n",
      "저장된 프레임 넘버 :  8000\n",
      "저장된 프레임 넘버 :  8025\n",
      "저장된 프레임 넘버 :  8050\n",
      "저장된 프레임 넘버 :  8075\n",
      "저장된 프레임 넘버 :  8100\n",
      "저장된 프레임 넘버 :  8125\n",
      "저장된 프레임 넘버 :  8150\n",
      "저장된 프레임 넘버 :  8175\n",
      "저장된 프레임 넘버 :  8200\n",
      "저장된 프레임 넘버 :  8225\n",
      "저장된 프레임 넘버 :  8250\n",
      "저장된 프레임 넘버 :  8275\n",
      "저장된 프레임 넘버 :  8300\n",
      "저장된 프레임 넘버 :  8325\n",
      "저장된 프레임 넘버 :  8350\n",
      "저장된 프레임 넘버 :  8375\n",
      "저장된 프레임 넘버 :  8400\n",
      "저장된 프레임 넘버 :  8425\n",
      "저장된 프레임 넘버 :  8450\n",
      "저장된 프레임 넘버 :  8475\n",
      "저장된 프레임 넘버 :  8500\n",
      "저장된 프레임 넘버 :  8525\n",
      "저장된 프레임 넘버 :  8550\n",
      "저장된 프레임 넘버 :  8575\n",
      "저장된 프레임 넘버 :  8600\n",
      "저장된 프레임 넘버 :  8625\n",
      "저장된 프레임 넘버 :  8650\n",
      "저장된 프레임 넘버 :  8675\n",
      "저장된 프레임 넘버 :  8700\n",
      "저장된 프레임 넘버 :  8725\n",
      "저장된 프레임 넘버 :  8750\n",
      "저장된 프레임 넘버 :  8775\n",
      "저장된 프레임 넘버 :  8800\n",
      "저장된 프레임 넘버 :  8825\n",
      "저장된 프레임 넘버 :  8850\n",
      "저장된 프레임 넘버 :  8875\n",
      "저장된 프레임 넘버 :  8900\n",
      "저장된 프레임 넘버 :  8925\n",
      "저장된 프레임 넘버 :  8950\n",
      "저장된 프레임 넘버 :  8975\n",
      "저장된 프레임 넘버 :  9000\n",
      "저장된 프레임 넘버 :  9025\n",
      "저장된 프레임 넘버 :  9050\n",
      "저장된 프레임 넘버 :  9075\n",
      "저장된 프레임 넘버 :  9100\n",
      "저장된 프레임 넘버 :  9125\n",
      "저장된 프레임 넘버 :  9150\n",
      "저장된 프레임 넘버 :  9175\n",
      "저장된 프레임 넘버 :  9200\n",
      "저장된 프레임 넘버 :  9225\n",
      "저장된 프레임 넘버 :  9250\n",
      "저장된 프레임 넘버 :  9275\n",
      "저장된 프레임 넘버 :  9300\n",
      "저장된 프레임 넘버 :  9325\n",
      "저장된 프레임 넘버 :  9350\n",
      "저장된 프레임 넘버 :  9375\n",
      "저장된 프레임 넘버 :  9400\n",
      "저장된 프레임 넘버 :  9425\n",
      "저장된 프레임 넘버 :  9450\n",
      "저장된 프레임 넘버 :  9475\n",
      "저장된 프레임 넘버 :  9500\n",
      "저장된 프레임 넘버 :  9525\n",
      "저장된 프레임 넘버 :  9550\n",
      "저장된 프레임 넘버 :  9575\n",
      "저장된 프레임 넘버 :  9600\n",
      "저장된 프레임 넘버 :  9625\n",
      "저장된 프레임 넘버 :  9650\n",
      "저장된 프레임 넘버 :  9675\n",
      "저장된 프레임 넘버 :  9700\n",
      "저장된 프레임 넘버 :  9725\n",
      "저장된 프레임 넘버 :  9750\n",
      "저장된 프레임 넘버 :  9775\n",
      "저장된 프레임 넘버 :  9800\n",
      "저장된 프레임 넘버 :  9825\n",
      "저장된 프레임 넘버 :  9850\n",
      "저장된 프레임 넘버 :  9875\n",
      "저장된 프레임 넘버 :  9900\n",
      "저장된 프레임 넘버 :  9925\n",
      "저장된 프레임 넘버 :  9950\n",
      "저장된 프레임 넘버 :  9975\n",
      "저장된 프레임 넘버 :  10000\n",
      "저장된 프레임 넘버 :  10025\n",
      "저장된 프레임 넘버 :  10050\n",
      "저장된 프레임 넘버 :  10075\n",
      "저장된 프레임 넘버 :  10100\n",
      "저장된 프레임 넘버 :  10125\n",
      "저장된 프레임 넘버 :  10150\n",
      "저장된 프레임 넘버 :  10175\n",
      "저장된 프레임 넘버 :  10200\n",
      "저장된 프레임 넘버 :  10225\n",
      "저장된 프레임 넘버 :  10250\n",
      "저장된 프레임 넘버 :  10275\n",
      "저장된 프레임 넘버 :  10300\n",
      "저장된 프레임 넘버 :  10325\n",
      "저장된 프레임 넘버 :  10350\n",
      "저장된 프레임 넘버 :  10375\n",
      "저장된 프레임 넘버 :  10400\n",
      "저장된 프레임 넘버 :  10425\n",
      "저장된 프레임 넘버 :  10450\n",
      "저장된 프레임 넘버 :  10475\n",
      "저장된 프레임 넘버 :  10500\n",
      "저장된 프레임 넘버 :  10525\n",
      "저장된 프레임 넘버 :  10550\n",
      "저장된 프레임 넘버 :  10575\n",
      "저장된 프레임 넘버 :  10600\n",
      "저장된 프레임 넘버 :  10625\n",
      "저장된 프레임 넘버 :  10650\n",
      "저장된 프레임 넘버 :  10675\n",
      "저장된 프레임 넘버 :  10700\n",
      "저장된 프레임 넘버 :  10725\n",
      "저장된 프레임 넘버 :  10750\n",
      "저장된 프레임 넘버 :  10775\n",
      "저장된 프레임 넘버 :  10800\n",
      "저장된 프레임 넘버 :  10825\n",
      "저장된 프레임 넘버 :  10850\n",
      "저장된 프레임 넘버 :  10875\n",
      "저장된 프레임 넘버 :  10900\n",
      "저장된 프레임 넘버 :  10925\n",
      "저장된 프레임 넘버 :  10950\n",
      "저장된 프레임 넘버 :  10975\n",
      "저장된 프레임 넘버 :  11000\n",
      "저장된 프레임 넘버 :  11025\n",
      "저장된 프레임 넘버 :  11050\n",
      "저장된 프레임 넘버 :  11075\n",
      "저장된 프레임 넘버 :  11100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 5/5 [02:58<00:00, 35.72s/item]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 프레임 넘버 :  11125\n",
      "저장된 프레임 넘버 :  11150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#전력구 이미지 분할 수행\n",
    "\n",
    "directory_path = '/home/seongmin/src/Python_WS/data/electric_tunnel'\n",
    "label = 'electric_tunnel'\n",
    "files = get_jpg_files_in_directory(directory_path)\n",
    "print('files : ', files)\n",
    "\n",
    "for f in tqdm(files, desc=\"Processing\", unit=\"item\"):\n",
    "  print(\"full_path : \", f)\n",
    "  file_name = f.split('/')[-1].split('.')[0]\n",
    "  print(\"file_name : \", file_name)\n",
    "  for i in get_image(f, file_name, label):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subfolders(directory):\n",
    "    subfolders = [f.path.split(\"/\")[-1] for f in os.scandir(directory) if f.is_dir()]\n",
    "    return subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jpg_files_image_directory(directory):\n",
    "  return glob(directory + '/*.jpg', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618의 총 파일 수 :  291\n",
    "- /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056의 총 파일 수 :  365\n",
    "- /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613의 총 파일 수 :  398\n",
    "- /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_160305의 총 파일 수 :  333\n",
    "- /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_161105의 총 파일 수 :  446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_annotate(image_dir, visual_dir, label_dir, weight, device, conf=0.1):\n",
    "    model = YOLO(weight)\n",
    "\n",
    "    image_list = glob(f'{image_dir}/*.jpg')\n",
    "\n",
    "    for image_path in image_list:\n",
    "        results = model.predict(image_path, device=device, conf=conf, stream=True)\n",
    "        for result in results:\n",
    "            class_ids = result.boxes.cls.int().tolist()  # noqa\n",
    "            if len(class_ids):\n",
    "                image_stem = os.path.basename(result.path).rsplit(\".\", 1)[0]\n",
    "\n",
    "                annotated = result.plot(line_width=2)\n",
    "                cv2.imwrite(f'{visual_dir}/{image_stem}.jpg', annotated)\n",
    "\n",
    "                boxes = result.boxes.xyxyn  # Boxes object for bbox outputs\n",
    "                kpts = result.keypoints.xyn\n",
    "                with open(f'{label_dir}/{image_stem}.txt', 'w') as f:\n",
    "                    for i in range(len(kpts)):\n",
    "                        kpt = kpts[i]\n",
    "                        if len(kpt) == 0:\n",
    "                            continue\n",
    "                        box = map(str, boxes[i].reshape(-1).tolist())\n",
    "                        keypoint = map(str, kpts[i].reshape(-1).tolist())\n",
    "                        f.write(f'{class_ids[i]} ' + ' '.join(box) + ' '.join(keypoint) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20230719_154618', '20230719_155056', '20230719_155613', '20230719_160305', '20230719_161105']\n",
      "/home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618의 총 파일 수 :  291\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8x-pose.pt to 'weights/yolov8x-pose.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133M/133M [00:06<00:00, 20.5MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6150.jpg: 384x640 1 person, 62.5ms\n",
      "Speed: 2.9ms preprocess, 62.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/7250.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/7100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6575.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/7125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2675.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6200.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2175.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5350.jpg: 384x640 (no detections), 20.5ms\n",
      "Speed: 1.5ms preprocess, 20.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/75.jpg: 384x640 1 person, 20.6ms\n",
      "Speed: 1.6ms preprocess, 20.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/575.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4000.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2550.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/7225.jpg: 384x640 1 person, 20.5ms\n",
      "Speed: 1.5ms preprocess, 20.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3325.jpg: 384x640 1 person, 20.7ms\n",
      "Speed: 1.6ms preprocess, 20.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3425.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/525.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1550.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3925.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6400.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1725.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/925.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/175.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/7025.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4675.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4525.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4800.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5550.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2500.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/625.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2075.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1250.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5725.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6050.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1325.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2150.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/600.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3225.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2300.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3075.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3175.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/375.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1625.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4775.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3800.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6525.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6375.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5000.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6600.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3600.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/7200.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5850.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3850.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6700.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/400.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5625.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/350.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1800.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6750.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2100.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4575.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4150.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/125.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5775.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2725.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/7175.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2750.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3525.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/900.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1575.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1200.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.9ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6850.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/650.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2025.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1350.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5800.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3750.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5650.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/50.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/325.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1300.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/725.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6650.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1825.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.4ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5175.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5475.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2625.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/7050.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6925.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3400.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4625.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/800.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2600.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2650.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2325.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3550.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3250.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3575.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6000.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4600.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4725.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3625.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6475.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6950.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3350.jpg: 384x640 2 persons, 20.2ms\n",
      "Speed: 1.7ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1375.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5275.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2450.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/7275.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6425.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1175.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6675.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1750.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5150.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/750.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2850.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/550.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6550.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3125.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2925.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5700.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2900.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6975.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1400.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2575.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3725.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/7150.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4700.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4375.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6900.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5925.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6625.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1600.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.4ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6250.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5525.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5825.jpg: 384x640 2 persons, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3675.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4075.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5400.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1925.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/675.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/7075.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4850.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2775.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3150.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3275.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4875.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5025.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4950.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6025.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3375.jpg: 384x640 2 persons, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3000.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4750.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4925.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4300.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4350.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4550.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5600.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6350.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/850.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3975.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4175.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5975.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1025.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4400.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/700.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4025.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5900.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2700.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1000.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2125.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6800.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3650.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5075.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1075.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1700.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5575.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1525.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5675.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2000.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1500.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6725.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4450.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2350.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2400.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1850.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3025.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4250.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1150.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4650.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6075.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5875.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1450.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4825.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/6175.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5750.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1650.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/475.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1225.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2800.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/4500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/975.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/25.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/250.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3700.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1675.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/150.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5250.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3475.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/5375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/3900.jpg: 384x640 1 person, 20.7ms\n",
      "Speed: 1.5ms preprocess, 20.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/7000.jpg: 384x640 1 person, 20.6ms\n",
      "Speed: 1.5ms preprocess, 20.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/1875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_154618/2250.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "/home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056의 총 파일 수 :  365\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7900.jpg: 384x640 (no detections), 20.8ms\n",
      "Speed: 1.6ms preprocess, 20.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6150.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7250.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7400.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/9100.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2825.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5450.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7425.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7100.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4050.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8800.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4125.jpg: 384x640 (no detections), 20.8ms\n",
      "Speed: 1.5ms preprocess, 20.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7875.jpg: 384x640 (no detections), 20.7ms\n",
      "Speed: 1.6ms preprocess, 20.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6225.jpg: 384x640 1 person, 20.7ms\n",
      "Speed: 1.5ms preprocess, 20.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2475.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6575.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2675.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2175.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/9050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2875.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5350.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/75.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/575.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4000.jpg: 384x640 2 persons, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2550.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8600.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8250.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7225.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8075.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1550.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3925.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6400.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/9075.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1725.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/925.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/175.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7025.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4675.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4800.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5550.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2500.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/625.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2075.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/200.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1250.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5725.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6050.jpg: 384x640 1 person, 20.4ms\n",
      "Speed: 1.6ms preprocess, 20.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2150.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/600.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3225.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/9125.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3075.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3175.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1625.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3800.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8650.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5000.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6600.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3600.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5850.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3850.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6700.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8550.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/400.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5625.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/350.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1800.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6750.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4575.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4150.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7600.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7700.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2725.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7175.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2750.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1575.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6850.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/650.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2025.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1350.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5800.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3750.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5650.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/50.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/325.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/725.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6650.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5175.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2625.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6925.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7475.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3400.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4625.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8725.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/800.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8750.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2600.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2650.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3550.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3250.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3575.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6000.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4600.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4725.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3625.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7850.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1950.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7750.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3350.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8575.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5275.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7825.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1175.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6675.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1750.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7675.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5150.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/750.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2850.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8025.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/550.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6550.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2925.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5700.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1400.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2575.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3725.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7150.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4700.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5925.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6625.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1600.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6250.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7925.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8150.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5425.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3675.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4075.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7975.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5400.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1925.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/675.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5225.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7075.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4850.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8625.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8350.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2775.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3150.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7650.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/9000.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5025.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8675.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6025.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3000.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/9025.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4750.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4925.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4350.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4550.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5600.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6350.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/850.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4175.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8850.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1025.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4400.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8175.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/700.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4025.jpg: 384x640 1 person, 20.4ms\n",
      "Speed: 1.5ms preprocess, 20.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7525.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7625.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8925.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2700.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1000.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6800.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3650.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8000.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5075.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1075.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.8ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1700.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7725.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5575.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5675.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7775.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2000.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6725.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2350.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7500.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2400.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1850.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2525.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3025.jpg: 384x640 1 person, 20.4ms\n",
      "Speed: 1.5ms preprocess, 20.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4250.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7950.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1150.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4650.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6075.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7575.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/6175.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5750.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8700.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1650.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2800.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8400.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8275.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/4500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/25.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7800.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/250.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3700.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1675.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/150.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5250.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/5375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7550.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/3900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7350.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/7000.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/1875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/8425.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155056/2250.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.4ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "/home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613의 총 파일 수 :  398\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7900.jpg: 384x640 1 person, 21.2ms\n",
      "Speed: 1.7ms preprocess, 21.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6150.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.9ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7250.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7400.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9100.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8800.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9625.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6575.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2675.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6200.jpg: 384x640 1 person, 20.7ms\n",
      "Speed: 1.5ms preprocess, 20.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2175.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9050.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5350.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/75.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/575.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8525.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7325.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4000.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2550.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8600.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8250.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8075.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1550.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9275.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3925.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6400.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9075.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1725.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/925.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/175.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7025.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4675.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4800.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5550.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/625.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2075.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/200.jpg: 384x640 1 person, 20.4ms\n",
      "Speed: 1.7ms preprocess, 20.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1250.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5725.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2150.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/600.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9125.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1125.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3075.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3175.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1625.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3800.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8650.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5000.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6600.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3600.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5850.jpg: 384x640 (no detections), 20.5ms\n",
      "Speed: 1.5ms preprocess, 20.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3850.jpg: 384x640 1 person, 20.7ms\n",
      "Speed: 1.5ms preprocess, 20.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6700.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8550.jpg: 384x640 (no detections), 20.4ms\n",
      "Speed: 1.7ms preprocess, 20.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/400.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7375.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5625.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9750.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/350.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1800.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6750.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2100.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4575.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4150.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8125.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7600.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7700.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2725.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7175.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2750.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1575.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9675.jpg: 384x640 1 person, 20.4ms\n",
      "Speed: 1.8ms preprocess, 20.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3500.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6850.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/650.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2025.jpg: 384x640 1 person, 20.7ms\n",
      "Speed: 1.6ms preprocess, 20.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1350.jpg: 384x640 1 person, 20.7ms\n",
      "Speed: 1.5ms preprocess, 20.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5800.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.7ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3750.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5650.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/50.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/325.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1300.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/725.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1475.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6650.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1825.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5175.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4425.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5475.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2625.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7050.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6925.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8200.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8825.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.7ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3400.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4625.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8725.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/800.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8750.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2600.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6825.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2650.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2325.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3550.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3250.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3575.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6000.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3300.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8875.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4600.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4725.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3625.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6950.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8975.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7850.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1950.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7750.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3350.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.8ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1050.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8575.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1375.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4100.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5275.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8300.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2450.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7825.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8500.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7275.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6425.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/950.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1175.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6675.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2275.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1750.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7675.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5150.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/750.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6775.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9925.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 2.3ms preprocess, 20.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2200.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.8ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2850.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.7ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8025.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/550.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6550.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2225.jpg: 384x640 2 persons, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3125.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2925.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5700.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2900.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5500.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6975.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1400.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2575.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3725.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3875.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7150.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5325.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4700.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4375.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9225.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6900.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5925.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/500.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9325.jpg: 384x640 1 person, 20.4ms\n",
      "Speed: 1.8ms preprocess, 20.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9150.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6625.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1600.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3450.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/300.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8775.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4325.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2425.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6250.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7300.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1100.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7925.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9950.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5525.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3050.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5825.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8150.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5425.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3675.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4075.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7975.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5400.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 2.2ms preprocess, 20.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/775.jpg: 384x640 1 person, 20.4ms\n",
      "Speed: 2.7ms preprocess, 20.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1925.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/675.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5225.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7075.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4850.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8625.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9350.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8350.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3150.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4475.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4200.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/225.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5125.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4875.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3950.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7650.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9000.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.8ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5025.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8675.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4950.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6025.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5100.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3375.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3000.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9600.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9025.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4750.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4925.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2950.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4300.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1275.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4350.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4550.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5600.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6350.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/850.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4175.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8450.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5975.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.8ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8850.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9250.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9550.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1025.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2375.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4400.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8175.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.8ms preprocess, 20.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/700.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.9ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8375.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4025.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8325.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7525.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7625.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8925.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8900.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5900.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2700.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1000.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 2.0ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2125.jpg: 384x640 1 person, 20.4ms\n",
      "Speed: 2.6ms preprocess, 20.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6800.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/100.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7450.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3650.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.8ms preprocess, 20.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9575.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.9ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8000.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9700.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5075.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1075.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1700.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8050.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7725.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5575.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5675.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7775.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2000.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1500.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9175.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6725.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4450.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2350.jpg: 384x640 1 person, 20.4ms\n",
      "Speed: 2.2ms preprocess, 20.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7500.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1775.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2400.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.7ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9850.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9300.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1850.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2525.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1425.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9775.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/3025.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8100.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9725.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4250.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9400.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6125.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.8ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7950.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1150.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4650.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6075.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5875.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/825.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.8ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6275.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9200.jpg: 384x640 (no detections), 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1450.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/4825.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/7575.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/6175.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1975.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/5750.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8700.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/8225.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1650.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/475.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.8ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/1225.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.8ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/9875.jpg: 384x640 1 person, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/seongmin/src/Python_WS/data/electric_tunnel/images/20230719_155613/2800.jpg: 384x640 1 person, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#auto annotation 실행\n",
    "\n",
    "root_directory = '/home/seongmin/src/Python_WS/data/electric_tunnel/images/'\n",
    "image_directory = get_subfolders(root_directory)\n",
    "image_directory = sorted(image_directory)\n",
    "print(image_directory)\n",
    "\n",
    "\n",
    "\n",
    "for image_folder in image_directory:\n",
    "  image_list = get_jpg_files_image_directory(root_directory + image_folder)\n",
    "  print(f\"{root_directory + image_folder}의 총 파일 수 : \", len(image_list))\n",
    "  \n",
    "  \n",
    "  image_dir = f'{root_directory}{image_folder}'\n",
    "  label_dir = f'{image_dir}/../labels/{image_folder}'\n",
    "  visual_dir = f'{image_dir}/../annotated{image_folder}'\n",
    "  \n",
    "  os.makedirs(label_dir, exist_ok=True)\n",
    "  os.makedirs(visual_dir, exist_ok=True)\n",
    "  weight = 'weights/yolov8x-pose.pt'\n",
    "  auto_annotate(image_dir,visual_dir,label_dir,weight=weight, device='0', conf=0.3)\n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
