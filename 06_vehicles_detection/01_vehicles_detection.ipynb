{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.24 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Quadro RTX 8000, 48586MiB)\n",
      "Setup complete âœ… (80 CPUs, 503.5 GB RAM, 631.5/915.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 55.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.44 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.24 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Quadro RTX 8000, 48586MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/dataset.yaml, epochs=30, time=None, patience=100, batch=5, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/train, name=vehiclesDetection, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/train/vehiclesDetection\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/home/kkt/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 50.7MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary: 225 layers, 3011823 parameters, 3011807 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/train/labels... 878 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 878/878 [00:00<00:00, 983.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/valid/labels... 250 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [00:00<00:00, 1067.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/train/vehiclesDetection/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005078125), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/vehiclesDetection\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30     0.623G      1.133      2.665      1.316         23        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:13<00:00, 12.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.549      0.377      0.419      0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30      0.64G      1.236      2.187      1.379          7        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:12<00:00, 14.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 20.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.364      0.411      0.384      0.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30      0.65G      1.227        2.1       1.37         25        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:12<00:00, 14.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 21.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.422      0.441      0.369      0.228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30     0.646G      1.276      2.077      1.399         13        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:11<00:00, 15.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 22.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.433      0.441       0.42       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30     0.646G      1.264      2.016      1.374          8        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:11<00:00, 15.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 22.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.433      0.453      0.442      0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30     0.646G      1.251      2.011      1.383          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:08<00:00, 19.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 22.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.483      0.431      0.433      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30     0.646G      1.201      1.843      1.346         14        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:08<00:00, 20.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 22.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.489      0.465      0.459      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30      0.64G        1.2      1.816      1.354         13        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:11<00:00, 15.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.683      0.423      0.523       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30     0.646G      1.138      1.769      1.304         12        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:10<00:00, 17.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 22.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.549      0.457       0.49      0.329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30     0.646G      1.144      1.707      1.321         15        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:10<00:00, 16.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.575      0.439      0.499      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30     0.646G      1.137      1.672      1.302          7        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:08<00:00, 20.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.547      0.427      0.477      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30     0.644G      1.113      1.624      1.297          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:08<00:00, 20.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.554      0.553      0.537      0.386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30     0.646G      1.059       1.51      1.242         10        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:09<00:00, 18.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.655      0.487      0.574      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30     0.646G      1.081        1.5      1.294         11        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:10<00:00, 16.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.489      0.539      0.539      0.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30     0.644G      1.031       1.41      1.234          8        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:10<00:00, 16.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 24.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.629      0.441      0.523      0.395\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30     0.644G      1.047      1.431      1.235          9        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:10<00:00, 16.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.654      0.485      0.561      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30     0.644G      1.034      1.345      1.232         10        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:10<00:00, 16.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.735      0.515      0.608       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30     0.646G     0.9959      1.324      1.221         15        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:11<00:00, 15.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.621      0.546       0.56      0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30     0.648G     0.9869      1.277       1.21         26        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:10<00:00, 16.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454       0.65      0.559      0.603      0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30     0.644G     0.9626      1.246        1.2          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:10<00:00, 16.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 24.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.618      0.616      0.611      0.449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30     0.638G      0.888      1.188      1.148          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:11<00:00, 15.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.617      0.597      0.616      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30     0.644G     0.8616      1.096      1.137          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:10<00:00, 16.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454       0.58      0.533      0.567      0.428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30     0.644G       0.83       1.01      1.109          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:11<00:00, 15.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.496      0.559       0.55      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30     0.644G     0.8182     0.9804      1.111          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:11<00:00, 15.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 24.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.672      0.566      0.601      0.465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30     0.644G     0.7733     0.8919      1.087          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:11<00:00, 15.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.668      0.569      0.614      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30     0.644G     0.7674     0.8326      1.076          6        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:11<00:00, 15.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.588       0.59      0.589      0.461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30     0.644G     0.7716     0.8367      1.078          9        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:11<00:00, 15.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.661      0.563      0.607       0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30     0.644G     0.7233     0.7654      1.046          7        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:11<00:00, 15.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.651      0.584       0.59       0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30     0.646G     0.7111     0.7436      1.044         11        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:10<00:00, 16.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 24.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.655      0.574      0.608      0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30     0.644G     0.6994     0.7092      1.033          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:08<00:00, 20.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 24.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.663      0.545      0.597      0.461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 0.102 hours.\n",
      "Optimizer stripped from runs/train/vehiclesDetection/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/train/vehiclesDetection/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/train/vehiclesDetection/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.24 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Quadro RTX 8000, 48586MiB)\n",
      "Model summary (fused): 168 layers, 3006623 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 20.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        454      0.618      0.597      0.616      0.479\n",
      "             Ambulance        250         64      0.733      0.875      0.854      0.757\n",
      "                   Bus        250         46      0.533      0.696      0.697      0.572\n",
      "                   Car        250        238      0.623      0.361      0.471      0.316\n",
      "            Motorcycle        250         46      0.638      0.652      0.635       0.43\n",
      "                 Truck        250         60      0.564        0.4      0.422      0.319\n",
      "Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/train/vehiclesDetection\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data='/home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/dataset.yaml',  # dataset path\n",
    "    epochs=30,  # number of epochs\n",
    "    batch=5,  # size of each image batch\n",
    "    imgsz=416,  # resize images to this size    \n",
    "    project='runs/train',  # save training results to project/name\n",
    "    name='vehiclesDetection',  # save training results to project/name  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/00dea1edf14f09ab_jpg.rf.3f17c8790a68659d03b1939a59ccda80.jpg: 416x416 1 Ambulance, 4.4ms\n",
      "image 2/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/00dea1edf14f09ab_jpg.rf.KJ730oDTFPdXdJxvSLnX.jpg: 416x416 1 Ambulance, 4.4ms\n",
      "image 3/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/00e481ea1a520175_jpg.rf.6e6a8b3b45c9a11d106958f88ff714ea.jpg: 416x416 2 Buss, 4.4ms\n",
      "image 4/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/00e481ea1a520175_jpg.rf.MV6sZ8QCFwFeMYaI2tHm.jpg: 416x416 2 Buss, 4.5ms\n",
      "image 5/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/08c8b73e0c2e296e_jpg.rf.7IkYAamjZhnwsoXSrwKt.jpg: 416x416 2 Buss, 4.5ms\n",
      "image 6/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/08c8b73e0c2e296e_jpg.rf.effa65856584463c08848031cab357b9.jpg: 416x416 2 Buss, 4.5ms\n",
      "image 7/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/10c26c6598677a1f_jpg.rf.USCbBYVcUICkLhuq07Lw.jpg: 416x416 1 Motorcycle, 4.4ms\n",
      "image 8/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/10c26c6598677a1f_jpg.rf.f72b2b91e750909f68fffeee777e9350.jpg: 416x416 1 Motorcycle, 4.5ms\n",
      "image 9/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/1ef77c61856d3b4b_jpg.rf.HZMSiUVx3WUcMIooJMZX.jpg: 416x416 1 Motorcycle, 4.6ms\n",
      "image 10/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/1ef77c61856d3b4b_jpg.rf.a528f50763101224fad39907062c5026.jpg: 416x416 1 Motorcycle, 4.6ms\n",
      "image 11/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/259ff749ac781352_jpg.rf.8acc4aba3916d2dd58c3acca8890194b.jpg: 416x416 3 Cars, 4.3ms\n",
      "image 12/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/259ff749ac781352_jpg.rf.CZyKDHyPjIcTpIwNJ2rd.jpg: 416x416 3 Cars, 4.5ms\n",
      "image 13/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/2c21c734126f9f69_jpg.rf.5b6a30b89f06d6dbe401038cb7caf396.jpg: 416x416 1 Ambulance, 4.6ms\n",
      "image 14/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/2c21c734126f9f69_jpg.rf.9G8Ajct2ynuOcQoTES9z.jpg: 416x416 1 Ambulance, 4.5ms\n",
      "image 15/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/2eaf88e3156629c6_jpg.rf.2a8LCMIPEihcmaF7wMjX.jpg: 416x416 1 Car, 4 Trucks, 4.4ms\n",
      "image 16/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/2eaf88e3156629c6_jpg.rf.73ce41f3e4820d02eecbb00c405e6e6e.jpg: 416x416 1 Car, 4 Trucks, 4.7ms\n",
      "image 17/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/31d30eccf56cac5f_jpg.rf.DPfttPJtcKnLajb1gulu.jpg: 416x416 2 Motorcycles, 4.3ms\n",
      "image 18/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/31d30eccf56cac5f_jpg.rf.c8541ffad78068c67ad369640d6c2b47.jpg: 416x416 2 Motorcycles, 4.6ms\n",
      "image 19/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/3281f85bb3265523_jpg.rf.3d2bbcf2b4bd95523d7be04566ae2565.jpg: 416x416 1 Car, 4.5ms\n",
      "image 20/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/3281f85bb3265523_jpg.rf.h2dkv1fIXvgeK5x8f1Te.jpg: 416x416 1 Car, 4.5ms\n",
      "image 21/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/3429c6851095a4c3_jpg.rf.2921b5c17bda3bda8b69e0f8b5e44894.jpg: 416x416 1 Car, 4.5ms\n",
      "image 22/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/3429c6851095a4c3_jpg.rf.fqPa3xt3eK2RXoQ756m6.jpg: 416x416 1 Car, 4.4ms\n",
      "image 23/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/479012386aa308fb_jpg.rf.24d80cdb95dae89bc61b36651306c45f.jpg: 416x416 1 Bus, 4.4ms\n",
      "image 24/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/479012386aa308fb_jpg.rf.VLWysXm9Sry0kGyATZBb.jpg: 416x416 1 Bus, 4.5ms\n",
      "image 25/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/47b09b34e24b4039_jpg.rf.9274b35afd28c89ed4221e69e765e71d.jpg: 416x416 3 Buss, 4.5ms\n",
      "image 26/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/47b09b34e24b4039_jpg.rf.SXhYsnLDkwnvDNU811ds.jpg: 416x416 3 Buss, 4.5ms\n",
      "image 27/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/4ecafc9a0bae8003_jpg.rf.2UbsFgyK4QxCrSNix6wM.jpg: 416x416 1 Truck, 4.5ms\n",
      "image 28/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/4ecafc9a0bae8003_jpg.rf.f9f2a4cdc2c519b8feeb3ab0c04a7e1d.jpg: 416x416 1 Truck, 4.5ms\n",
      "image 29/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/567af04eef831f07_jpg.rf.b4410b0bb9811109a262c377ec82c6bf.jpg: 416x416 (no detections), 4.3ms\n",
      "image 30/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/567af04eef831f07_jpg.rf.zOgs6D5m0Qg5DNYOGw83.jpg: 416x416 (no detections), 4.4ms\n",
      "image 31/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/58163cb625c30451_jpg.rf.f224c9704e2d5d99e2da9e3815ce4374.jpg: 416x416 1 Car, 4.4ms\n",
      "image 32/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/58163cb625c30451_jpg.rf.qzv8RVHFUESFStEECs8Y.jpg: 416x416 1 Car, 4.5ms\n",
      "image 33/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/59b1c028bd8b08dc_jpg.rf.7cee04415facc914c97d31374c550472.jpg: 416x416 1 Bus, 4.5ms\n",
      "image 34/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/59b1c028bd8b08dc_jpg.rf.hZvI4yexc1c6709HMKkq.jpg: 416x416 1 Bus, 4.4ms\n",
      "image 35/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/61b330a7098fba8b_jpg.rf.PvkjLyR5FqHNWALMC9tR.jpg: 416x416 2 Cars, 4.6ms\n",
      "image 36/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/61b330a7098fba8b_jpg.rf.d26d49aaf1da085ec08dc3e6cbb030b8.jpg: 416x416 2 Cars, 4.5ms\n",
      "image 37/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/621edf1632f6f63c_jpg.rf.caa3c8e665a2cccfbaf94d9c70999e94.jpg: 416x416 (no detections), 4.5ms\n",
      "image 38/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/621edf1632f6f63c_jpg.rf.mHET2dhSa787SiBvJxBE.jpg: 416x416 (no detections), 4.6ms\n",
      "image 39/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/64918de984156adf_jpg.rf.b1255cf890c76ce326916ffcc9e2ca2d.jpg: 416x416 1 Car, 4.7ms\n",
      "image 40/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/64918de984156adf_jpg.rf.oG9xHqC6y9JQHQyqJ3y8.jpg: 416x416 1 Car, 4.6ms\n",
      "image 41/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/6a16101bb9217422_jpg.rf.3d3f8d8294a272eb9272eaf3fa871751.jpg: 416x416 1 Bus, 4.6ms\n",
      "image 42/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/6a16101bb9217422_jpg.rf.8WKpVgqqjh9DUhom2WOC.jpg: 416x416 1 Bus, 4.5ms\n",
      "image 43/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/6bc019fc59fce6bc_jpg.rf.VJAhyBJnfIldtscisZ3p.jpg: 416x416 2 Cars, 4.5ms\n",
      "image 44/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/6bc019fc59fce6bc_jpg.rf.c948d1ae1b4d24a960336d334ef7b6ea.jpg: 416x416 2 Cars, 4.4ms\n",
      "image 45/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/6d5d24e86c1ff260_jpg.rf.f7acfa6e4c8049353976699fcd4d515f.jpg: 416x416 1 Bus, 4.5ms\n",
      "image 46/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/6d5d24e86c1ff260_jpg.rf.xc7Xmsiy5QL5Ux1uJ7Lv.jpg: 416x416 1 Bus, 4.4ms\n",
      "image 47/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/6dce4caa5b30c32a_jpg.rf.99b1738867fe889250ccde59b52715fb.jpg: 416x416 1 Car, 4.6ms\n",
      "image 48/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/6dce4caa5b30c32a_jpg.rf.ptCAjjugxBjYRY2Pe2IP.jpg: 416x416 1 Car, 4.5ms\n",
      "image 49/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/6e85d4ef31b5eed3_jpg.rf.01ea5ec813abb42ce956650ad5ea6a35.jpg: 416x416 1 Car, 4.4ms\n",
      "image 50/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/6e85d4ef31b5eed3_jpg.rf.AOgdpzbR1UnLQJvr9mfx.jpg: 416x416 1 Car, 4.5ms\n",
      "image 51/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/6f6e6ee0f2f3e68a_jpg.rf.5c3fe7658919995026da87e1d5fa6c24.jpg: 416x416 1 Car, 4.5ms\n",
      "image 52/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/6f6e6ee0f2f3e68a_jpg.rf.hS7GaqosJzGzkS9RD7Wz.jpg: 416x416 1 Car, 4.4ms\n",
      "image 53/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/72e16f7160358c50_jpg.rf.43ab0d7684390f4c28a098404164f5f8.jpg: 416x416 1 Bus, 4.5ms\n",
      "image 54/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/72e16f7160358c50_jpg.rf.p1glBr5tchCYf248Nu0S.jpg: 416x416 1 Bus, 4.9ms\n",
      "image 55/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/778f80f86cd35fca_jpg.rf.74dd531b37bb62f4d40e624dcd9d44d3.jpg: 416x416 4 Cars, 4.5ms\n",
      "image 56/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/778f80f86cd35fca_jpg.rf.rvpvlWkcR8MNONYPfAvI.jpg: 416x416 4 Cars, 4.5ms\n",
      "image 57/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/7b1c58ed404a2ca1_jpg.rf.79fBvGzcTdK9pFforgXa.jpg: 416x416 1 Car, 4.5ms\n",
      "image 58/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/7b1c58ed404a2ca1_jpg.rf.8316aa9e4a9561772111bf4edaca3737.jpg: 416x416 1 Car, 4.6ms\n",
      "image 59/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/7baf801decfab71a_jpg.rf.1atdX9M2VU1J7hd8ePoy.jpg: 416x416 1 Car, 4.5ms\n",
      "image 60/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/7baf801decfab71a_jpg.rf.21c80f0a2bff5314b583936be2149156.jpg: 416x416 1 Car, 4.4ms\n",
      "image 61/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/82a06e5f21d877a5_jpg.rf.0CLEM5oy7jeOH6eRbFBl.jpg: 416x416 1 Bus, 4.6ms\n",
      "image 62/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/82a06e5f21d877a5_jpg.rf.3669fd7f7e84394cf6a9839ed9a984e3.jpg: 416x416 1 Bus, 4.4ms\n",
      "image 63/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/861be2a154763b07_jpg.rf.6a7c5056da0a16a78233ed4c49deee25.jpg: 416x416 1 Ambulance, 4.5ms\n",
      "image 64/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/861be2a154763b07_jpg.rf.nvXuwhf3jtMFPo9ZSdaA.jpg: 416x416 1 Ambulance, 4.4ms\n",
      "image 65/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/86f2efc6efadba44_jpg.rf.0eyOFjUiqZtQ2OxnzB4C.jpg: 416x416 1 Car, 4.5ms\n",
      "image 66/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/86f2efc6efadba44_jpg.rf.17b9e1c5386e8cd067f776f95f2139a7.jpg: 416x416 1 Car, 4.6ms\n",
      "image 67/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/8ccad0d567bc7aad_jpg.rf.bbeeab003239f3c9854ed0d97fbc3520.jpg: 416x416 3 Cars, 4.4ms\n",
      "image 68/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/8ccad0d567bc7aad_jpg.rf.c9Avid7rlCLPzDmR8Jm9.jpg: 416x416 3 Cars, 4.5ms\n",
      "image 69/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/958efc095c686ef6_jpg.rf.56nx09qgfDF5ZntcEzXO.jpg: 416x416 1 Car, 4.5ms\n",
      "image 70/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/958efc095c686ef6_jpg.rf.963de21446d75d8452e417c3c262b9a8.jpg: 416x416 1 Car, 4.5ms\n",
      "image 71/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/95bf6406c152cf40_jpg.rf.2KlhzCSeifqpfUPfwyW9.jpg: 416x416 2 Cars, 4.6ms\n",
      "image 72/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/95bf6406c152cf40_jpg.rf.58a7d5b1c4309ad003108642c51ae8b3.jpg: 416x416 2 Cars, 4.6ms\n",
      "image 73/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/9876c285fe7bc3a0_jpg.rf.7aa68726bc91a7c26d99c23dd79cc833.jpg: 416x416 1 Ambulance, 4.5ms\n",
      "image 74/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/9876c285fe7bc3a0_jpg.rf.iBBVQWEpeWVbehE5MJ6Q.jpg: 416x416 1 Ambulance, 4.6ms\n",
      "image 75/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/9ca8e20e0869f289_jpg.rf.4bb7001185dba72f41b354c6235e79cb.jpg: 416x416 (no detections), 4.7ms\n",
      "image 76/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/9ca8e20e0869f289_jpg.rf.ScBMQ9VslO942N7rh8rz.jpg: 416x416 (no detections), 4.6ms\n",
      "image 77/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/9d2d424099458956_jpg.rf.9cc91fddce7c7441e0f085d139b62aac.jpg: 416x416 1 Ambulance, 4.7ms\n",
      "image 78/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/9d2d424099458956_jpg.rf.vihT0YRoLD0QuODDlBz7.jpg: 416x416 1 Ambulance, 4.7ms\n",
      "image 79/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/9fdf0bf1160fca8e_jpg.rf.183a3d9dfcbbd5ad78f2148712430881.jpg: 416x416 2 Motorcycles, 4.7ms\n",
      "image 80/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/9fdf0bf1160fca8e_jpg.rf.ERTEMjgijaUbIUeFSoNX.jpg: 416x416 2 Motorcycles, 4.6ms\n",
      "image 81/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/a3cffcdbff959432_jpg.rf.1f1f8cfcdfe052a8ec72e63b11889b66.jpg: 416x416 1 Car, 1 Truck, 4.6ms\n",
      "image 82/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/a3cffcdbff959432_jpg.rf.4MQ1NmvMx33nwLe9QSvu.jpg: 416x416 1 Car, 1 Truck, 4.7ms\n",
      "image 83/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/a7674f15d9b1f35f_jpg.rf.7bbd38887231affc55a0083cfd2f422e.jpg: 416x416 1 Ambulance, 4.6ms\n",
      "image 84/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/a7674f15d9b1f35f_jpg.rf.pL09u0Oz8DRvTB3AnBXT.jpg: 416x416 1 Ambulance, 4.6ms\n",
      "image 85/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/aed83d879a22a6c4_jpg.rf.ada6c87c88d32689f79e3a03c9ebd314.jpg: 416x416 1 Motorcycle, 4.8ms\n",
      "image 86/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/aed83d879a22a6c4_jpg.rf.jXuDPuNwGM96NxEjG3PY.jpg: 416x416 1 Motorcycle, 4.6ms\n",
      "image 87/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/b3736bcf6bec5308_jpg.rf.988ed2199cddfaecb34a83859649121b.jpg: 416x416 1 Bus, 4.6ms\n",
      "image 88/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/b3736bcf6bec5308_jpg.rf.U5Fn1b2aP6gpWq3MBgO6.jpg: 416x416 1 Bus, 4.6ms\n",
      "image 89/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/b3b144afc677916a_jpg.rf.XLqzSaCBgbZw1v09pRTm.jpg: 416x416 2 Cars, 4.7ms\n",
      "image 90/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/b3b144afc677916a_jpg.rf.ed98057677d7c2972ab5bdd7f2325003.jpg: 416x416 2 Cars, 4.6ms\n",
      "image 91/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/b52533fcc735c023_jpg.rf.74a2f1bbd4d5714181e21e7ef1296b1b.jpg: 416x416 1 Ambulance, 2 Cars, 4.7ms\n",
      "image 92/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/b52533fcc735c023_jpg.rf.YRJXvJEWcsvHdbezWTT5.jpg: 416x416 1 Ambulance, 2 Cars, 4.6ms\n",
      "image 93/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/b778de31063c80ef_jpg.rf.45289b648d6167a0f218c0ac1087b351.jpg: 416x416 1 Truck, 4.5ms\n",
      "image 94/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/b778de31063c80ef_jpg.rf.wETmgEiHs4taG421vJ6e.jpg: 416x416 1 Truck, 4.5ms\n",
      "image 95/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/b7cc71d4f2108d9c_jpg.rf.7c0e6624c115812a7ae5a2cabfd915b8.jpg: 416x416 1 Ambulance, 4.6ms\n",
      "image 96/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/b7cc71d4f2108d9c_jpg.rf.k85zClsDgxtxBGb6PUbH.jpg: 416x416 1 Ambulance, 4.5ms\n",
      "image 97/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/be3f71308b3598e9_jpg.rf.0895dab43842c01bcb8afc8b99d91c21.jpg: 416x416 1 Truck, 4.5ms\n",
      "image 98/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/be3f71308b3598e9_jpg.rf.u0lWU3LrXooFaQYTPa34.jpg: 416x416 1 Truck, 4.7ms\n",
      "image 99/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/beb59084f52dcb04_jpg.rf.60bc1675363e3e06d2f30510078d38e8.jpg: 416x416 1 Car, 4.6ms\n",
      "image 100/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/beb59084f52dcb04_jpg.rf.nB0qeYmJIl0llnmILG3Q.jpg: 416x416 1 Car, 4.6ms\n",
      "image 101/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/c094d0187caf81e3_jpg.rf.0d7e3eb391b1d43b1bdcceea7e1a6ce5.jpg: 416x416 1 Ambulance, 4.5ms\n",
      "image 102/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/c094d0187caf81e3_jpg.rf.75K3um7PpnqbqxUwbVSN.jpg: 416x416 1 Ambulance, 4.7ms\n",
      "image 103/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/c0a105b4fe3a7c55_jpg.rf.28745179cd0f87dc9cae886872f95263.jpg: 416x416 1 Bus, 1 Car, 4.7ms\n",
      "image 104/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/c0a105b4fe3a7c55_jpg.rf.TtrieGEGo7xyvdhMBtWt.jpg: 416x416 1 Bus, 1 Car, 4.6ms\n",
      "image 105/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/c1f88290d602f0e6_jpg.rf.ffe763bba24511dc402dcbac00b9ad34.jpg: 416x416 1 Car, 4.6ms\n",
      "image 106/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/c1f88290d602f0e6_jpg.rf.mQMBMSP5KAanVt15Z7Ji.jpg: 416x416 1 Car, 4.4ms\n",
      "image 107/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/c6942c8aa585dfeb_jpg.rf.25d55631f85499304e942713bbcd00a2.jpg: 416x416 (no detections), 4.6ms\n",
      "image 108/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/c6942c8aa585dfeb_jpg.rf.b19GcwKWIiFhEzZHUAQJ.jpg: 416x416 (no detections), 4.5ms\n",
      "image 109/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/c89a75a0fa5c2df9_jpg.rf.8fa102a61822cd10430764e3caf80f94.jpg: 416x416 1 Motorcycle, 4.3ms\n",
      "image 110/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/c89a75a0fa5c2df9_jpg.rf.Q6UrdVqikAXU96NdIhpL.jpg: 416x416 1 Motorcycle, 4.6ms\n",
      "image 111/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/cf165ec304d2b2dc_jpg.rf.1038a595a2a468537b6b88d3abeb03c4.jpg: 416x416 1 Car, 4.6ms\n",
      "image 112/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/cf165ec304d2b2dc_jpg.rf.EBBLjKokT5TYAEPvd35E.jpg: 416x416 1 Car, 4.7ms\n",
      "image 113/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/d66aabbb1f7299cc_jpg.rf.27774c8e4188c1c8b62075beac6af14a.jpg: 416x416 1 Car, 4.6ms\n",
      "image 114/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/d66aabbb1f7299cc_jpg.rf.BmdIwlEED5bAslMh9Qib.jpg: 416x416 1 Car, 4.6ms\n",
      "image 115/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/e36e433eed49a09d_jpg.rf.8826d7fb567c1288c0188105137f280a.jpg: 416x416 1 Bus, 4.7ms\n",
      "image 116/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/e36e433eed49a09d_jpg.rf.vp4voN7BUsf5abwtFHbx.jpg: 416x416 1 Bus, 4.7ms\n",
      "image 117/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/e4029e591e9568b4_jpg.rf.7d1631ccd8fdcc764c4198e44ad121b4.jpg: 416x416 1 Car, 4.7ms\n",
      "image 118/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/e4029e591e9568b4_jpg.rf.NmOp4UE6HuJwbOWoMWHY.jpg: 416x416 1 Car, 4.6ms\n",
      "image 119/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/f00ec0093e986e99_jpg.rf.788065bc895796a1b381a68bb709d678.jpg: 416x416 4 Cars, 4.6ms\n",
      "image 120/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/f00ec0093e986e99_jpg.rf.NXMKhuok0UUZl1iUn9IE.jpg: 416x416 4 Cars, 4.5ms\n",
      "image 121/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/fb70621f1a194c73_jpg.rf.9WDZMyHpWqgrKoWWl23R.jpg: 416x416 2 Motorcycles, 4.6ms\n",
      "image 122/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/fb70621f1a194c73_jpg.rf.eeb3adf5c549a03fd9f6a0dd099ea05c.jpg: 416x416 2 Motorcycles, 4.7ms\n",
      "image 123/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/fca5c9c8f0276eff_jpg.rf.e37fa19b7839f09970da3e8c72e6c58e.jpg: 416x416 (no detections), 4.8ms\n",
      "image 124/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/fca5c9c8f0276eff_jpg.rf.vA6S9lDbrVuvoA2aoplG.jpg: 416x416 (no detections), 4.7ms\n",
      "image 125/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/fcbbda4f0678bfcf_jpg.rf.ba5680ddca55276fe0495e0622f5af0d.jpg: 416x416 3 Cars, 4.6ms\n",
      "image 126/126 /home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images/fcbbda4f0678bfcf_jpg.rf.oaHMZCzfjwXi0airgLrZ.jpg: 416x416 3 Cars, 4.3ms\n",
      "Speed: 0.8ms preprocess, 4.5ms inference, 0.8ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns/predict/vehiclesDetection\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('/home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/runs/train/vehiclesDetection/weights/best.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "\n",
    "results = model.predict(\n",
    "    source='/home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images',\n",
    "    conf=0.50,\n",
    "    project='runs/predict',\n",
    "    name='vehiclesDetection',\n",
    "    save=True,\n",
    "    imgsz=416,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('/home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/runs/train/vehiclesDetection/weights/best.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "\n",
    "results = model.predict(\n",
    "    source='/home/kkt/src/python_ws/Yolo/Yolo_Basic/06_vehicles_detection/Dataset/test/images',\n",
    "    conf=0.50,\n",
    "    project='runs/predict',\n",
    "    name='vehiclesDetection',\n",
    "    save=True,\n",
    "    imgsz=416,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
